{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Майнор по Анализу Данных, Группа ИАД-2\n",
    "## Домашнее задание №2: Классификация текстовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr\\>\n",
    "В задании вы будете решать задачу бинарной классификации текстов. Вы познакомитесь с основными инструментами sklearn, необходимыми для обработки текстов. Перед применением методов sklearn внимательно читайте документацию к ним: это полезно и помогает делать меньше ошибок.\n",
    "\n",
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 1 мая 2017, 9:00 <br\\>\n",
    "\n",
    "При отправлении ДЗ на почту `hse.minor.dm+X@gmail.com`, X = 3 или 4 (ИАД 3 или ИАД4), указывайте фамилию в названии файла, а тему письма оформляйте в следующем виде:<br\\>\n",
    "** [HW2, ИАД-X] Фамилия Имя **<br\\>\n",
    "\n",
    "Сопровождайте ваш код изображеними, комментариями и выводами. <br\\>\n",
    "Имейте ввиду, что на некоторые задачи нет единственного верного и полного ответа. Чем больше информации вы сможете извлечь, аргументированных выводов сформулировать, тем лучше.\n",
    "__Старайтесь не копировать похожие участки кода. Везде, где это возможно, оформляйте код в функцию.__\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания.\n",
    "<hr\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Чтобы узнать свой вариант, введите Вашу фамилию на русском языке в соответвующее поле ниже и запустите ячейку:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваш вариант -  2\n"
     ]
    }
   ],
   "source": [
    "name = \"БобровскихГлеб\" # Ваши ФамилияИмя\n",
    "\n",
    "alp = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "w = [4, 42, 21, 21, 34,  1, 44, 26, 18, 43, 38, 26, 18, 43,  3, 49, 45,\n",
    "        7, 42, 25,  4,  9, 36, 33, 31, 29,  5, 31,  4, 19, 24, 27, 33]\n",
    "d = dict(zip(alp, w))\n",
    "variant =  sum([d[el] for el in name.lower()]) % 2 + 1\n",
    "print(\"Ваш вариант - \", variant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Варианты</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от варианта нужно будет научиться определять...\n",
    "\n",
    "**1.** ...является ли SMS сообщение спамом? \n",
    "* Зайдите на [страничку с данными](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) на сайте репозитория UCI.\n",
    "* Нажмите на «Data Folder», скачайте и распакуйте архив.\n",
    "* Открыть SMSSpamCollection можно с помощью pd.read_csv, указав `sep='\\t'`.\n",
    "\n",
    "**2.** ...положительна или отрицательна рецензия на фильм?\n",
    "* Зайдите на [страничку с данными](http://www.cs.cornell.edu/people/pabo/movie-review-data/) на сайте Корнельского университета.\n",
    "* Нажмите на «polarity dataset v2.0» и распакуйте архив. \n",
    "* Каждый текстовый файл соответствует одной рецензии. Вам придётся [построить список всех файлов в папке](http://stackoverflow.com/questions/3207219/how-to-list-all-files-of-a-directory), а затем последовательно открыть их и прочитать тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_text(s):\n",
    "    # Removes all characters from string except letters and digits and convert letters to lowercase\n",
    "    return re.sub(\"[^a-zA-Z0-9]\", \" \", s.lower())\n",
    "#explain regular expression:\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = '/home/bobrg/anaconda3/txt_sentoken/pos'\n",
    "txt = []\n",
    "txt = [convert_text(open(join(mypath, f), 'r').read())for f in listdir(mypath)\n",
    "             if isfile(join(mypath, f))]\n",
    "labels = [1] * len(txt)\n",
    "mypath = '/home/bobrg/anaconda3/txt_sentoken/neg'\n",
    "txt.extend([convert_text(open(join(mypath, f), 'r').read()) for f in listdir(mypath)\n",
    "                               if isfile(join(mypath, f))])\n",
    "labels.extend([0] * (len(onlyfiles) - len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1\n",
    "#### Классификация текстовых сообщений (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Загрузите исходные данные --- список текстов и список соответствующих им меток</li>\n",
    "    <li>Разбейте объекты на обучающее (train) и тестовое подможества (test) в пропорции 7:3</li>\n",
    "    <li>Переведите текстовые данные в векторный вид. Для этого воcпользуйтесь средствами sklearn для конвертации текста в векторы TF-IDF (настраивать только на обучающем подмножестве, n-gram=1, слова приведите в нижний регистр)</li>\n",
    "    <li>Постройте на обучающем подмножестве следующие модели классификации:\n",
    "        <ul>\n",
    "            <li>K-ближайших соседей ($n=5$)</li>\n",
    "            <li>Логистическая регрессия ($C=1$)</li>\n",
    "            <li>Мультиномиальный наивный Байес ($\\alpha=1$)</li> \n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Определите качество классификации (по доле правильных классификаций) на тестовом подмножестве</li>\n",
    "    <li>Определите с помощью timeit время обучения и предсказания (на тестовом подмножестве) </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 12345 # для всех объектов/методов/моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Параметры логистической регрессии\n",
    "```\n",
    "penalty='l2'\n",
    "fit_intercept=True\n",
    "max_iter=100\n",
    "C=1\n",
    "solver=\"lbfgs\"\n",
    "random_state=12345\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(txt, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) / len(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация текстов\n",
    "\n",
    "EXPAND!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer(ngram_range=(1, 1))\n",
    "df = pd.DataFrame(data=count_vec.fit_transform(X_train).toarray(),\n",
    "                  columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(use_idf=False)\n",
    "df_train = transformer.fit_transform(np.asarray(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to make transformation:\n",
    "```\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "df_train = TfidfVectorizer(lowercase=True,ngram_range=(1,1)).fit_transform(X_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add sparse matrix explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1400x34188 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 469519 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение моделей:\n",
    "* KNN\n",
    "* LogisticRegression\n",
    "* MultinomialNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "knc.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.13 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit knc.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=12345, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logr = LogisticRegression(penalty='l2', fit_intercept=True, max_iter=100,\n",
    "                          C=1, solver=\"lbfgs\", random_state=12345)\n",
    "logr.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 324 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit logr.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.24 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit mnb.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение прогноза на тестовой подвыборке.\n",
    "Векторизуем тексты из теста и проверим предсказания обученых моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<600x34188 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 191310 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = transformer.transform(count_vec.transform(X_test))\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yy_knc = knc.predict(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.463333333333\n",
      "accuracy score 0.536666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "print('mae:', mean_absolute_error(yy_knc, y_test))\n",
    "print('accuracy score', accuracy_score(yy_knc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 264 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit knc.predict(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yy_lgr = logr.predict(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.261666666667\n",
      "accuracy score: 0.738333333333\n"
     ]
    }
   ],
   "source": [
    "print('mae:', mean_absolute_error(yy_lgr, y_test))\n",
    "print('accuracy score:', accuracy_score(yy_lgr, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 527 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit logr.predict(df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "µs - microseconds - WOW! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yy_mnb = mnb.predict(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.273333333333\n",
      "accuracy score: 0.726666666667\n"
     ]
    }
   ],
   "source": [
    "print('mae:', mean_absolute_error(yy_mnb, y_test))\n",
    "print('accuracy score:', accuracy_score(yy_mnb, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit mnb.predict(df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пояснения по результатам:\n",
    "\n",
    "Fitting time:\n",
    "* Дольше всего настраивается Логистическая регрессия, поскольку ей нужно настроить параметры сигмоиды, чтобы максимизировать функцию правдоподобия. Для этого применяется метод градиентного спуска, который и дает проигрыш во времени настройки.\n",
    "* Меньше всего времени на настройку тратит модель K Nearest Neighbours, поскольку она лишь запоминает выборку.\n",
    "\n",
    "Prediction time:\n",
    "На предсказании модели ведут себя противоположно своему поведению на настройке, т.е.:\n",
    "* Дольше всего предсказывает модель KNN, поскольку она должна померить расстояния евклидовой метрикой для каждого элемента из теста и каждого элемента из заученого трейна.\n",
    "* Меньше времени тратит Логистическая регрессия, поскольку ????\n",
    "\n",
    "What about MNB? (TODO: Expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2.\n",
    "#### Применение k-folds (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>1. Повторите решение задачи 1, но вместо одного разделения на обучение и контроль используйте разбиение k-folds (k=4). Вам понадобится повторить все действия 4 раза. <br>\n",
    "2. Какой классификатор показывал лучшее/худшее качество на тестовой выборке? А при k-folds разбиении? Как вы думаете, обязательно ли в данной задаче оценивать качество на кросс-валидации, или достаточно отложить контрольную выборку и оценивать качество на ней?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 12345 # для всех объектов/методов/моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "#to reduce code :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def kfold(model, data, labels, k):\n",
    "    tmp_model = model\n",
    "    tfidfvec = TfidfVectorizer(lowercase=True, ngram_range=(1,1))\n",
    "    kfld = KFold(n_splits=k, random_state=12345, shuffle=True)\n",
    "    \n",
    "    y_pred = np.zeros(len(labels))\n",
    "    \n",
    "    for i_train, i_test in kfld.split(data):\n",
    "        tmp = tfidfvec.fit_transform(data[i_train])\n",
    "        \n",
    "        X_train, X_test = tmp, tfidfvec.transform(data[i_test])\n",
    "        \n",
    "        y_train = labels[i_train]\n",
    "        \n",
    "        tmp_model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred[i_test] = tmp_model.predict(X_test)\n",
    "    print(accuracy_score(y_pred, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------KNN--------------------\n",
      "0.575\n",
      "-------------------LR--------------------\n",
      "0.8195\n",
      "-------------------MNB--------------------\n",
      "0.7935\n"
     ]
    }
   ],
   "source": [
    "print('-------------------KNN--------------------')\n",
    "kfold(knc, np.asarray(onlyfiles), np.asarray(labels), 4)\n",
    "print('-------------------LR--------------------')\n",
    "kfold(logr, np.asarray(onlyfiles), np.asarray(labels), 4)\n",
    "print('-------------------MNB--------------------')\n",
    "kfold(mnb, np.asarray(onlyfiles), np.asarray(labels), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пояснения по результатам:\n",
    "\n",
    "KFold разбиение на 4 фолдах улучшело результат предсказания моделей, но если с KNN (при k = 5) улучшение заметное, то с Логистической регрессией и Наивным Байесом улучшения едва заметны.\n",
    "(WHY? TODO: Expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3.\n",
    "#### Выбор модели (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:15px;\">1. Используя данные из задачи 1, разбейте обучающее подмножество (train) с использованием k-folds (k=4) <br>\n",
    "2. Рассмотрим следующие варианты значений гиперпараметров для наших классификаторов:  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>K-ближайших соседей</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns = np.arange(1, 150, 20) # количество соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Логистическая регрессия</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = np.logspace(-2, 10, 8, base=10) # параметр регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Мультиномиальный наивный Байес</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-4, 1, 8, base=10) # сглаживающий параметр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding-left:15px;\"> Найдите оптимальные значения гиперпараметров для классификаторов на кросс-валидации. Для этого постройте графики (гиперпараметр)-(качество) на обучении и валидации. <br> _Пояснение:_ вы разбили обучающую выборку на 4 блока. Для каждого значения гиперпараметра 4 раза повторите следующее: берем 3 блока для обучения, по ним настраиваем  TfIdf и обучаем классификатор, считаем качество на этих блоках (качество на обучении) и на оставшемся (качество на валидации). Итоговое значение качества на обучении для данного значения гиперпараметра - это среднее четырех полученных значений качества на обучении, то же самое с итоговым значением качества на валидации.  <br>\n",
    "3. 3 настроенные модели обучите на всем обучающем подмножестве (train) и протестируйте на тестовом (test). Определите время обучения и предсказания (см. задачу 1 п. 6)<br>\n",
    "4. Повторите шаги 2-4 для n-gram=2<br>\n",
    "5. Выведите итоговые данные по всем методам для лучших моделей (метод, n-gram, значение параметра модели, время обучения, время предсказания, доля правильных классификаций)<br>\n",
    "6. Сделайте выводы по полученным результатам: <ul>\n",
    "<li>какой метод показал наилучшее качество на обучении? на валидации? на тестовой выборке? Если это разные классификаторы, подумайте, почему так происходит. Если один и тот же, в чем его преимущества перед остальными?</li>\n",
    "<li>велика ли разница между качеством на обучении и на валидации? на валидации и контроле? Почему так происходит?</li>\n",
    "<li>что означает n-gram=2? Улучшилось ли качество при переходе от n-gram=1 к n-gram=2? Предложите свои идеи, почему.</li>\n",
    "<li>есть ли связь между качеством классификации и временем обучения/предсказания? какой классификатор обучается медленнее всего? медленнее всего делает предсказания? В чем причина?</li>\n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 12345 # для всех объектов/методов/моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим гиперпараметры моделей.\n",
    "Создадим функцию, чтобы избежать дубликации кода (DRY) и последовательно замеряем с ней, как зависит \n",
    "результат предсказания модели от разных параметров. Выборку в этот раз возьмем тренировочную, которую\n",
    "определили в задании 1 и поделим ее на 4-ре фолда на 3-ех из которых будем обучать модель, а на оставшемся\n",
    "валидироваться. Для определения результата обучения и валидации на выборке возьмем среднее по полученным\n",
    "результатам. Повторяем замеры для каждого параметра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hyperparams_info(model, data, labels, ngrams):\n",
    "    tmp = model\n",
    "    kfld=KFold(n_splits=4, random_state=12345, shuffle=True)\n",
    "    qual_train = []\n",
    "    qual_valid = []\n",
    "    \n",
    "    for i_tr, i_tst in kfld.split(data):\n",
    "        tfidfvec = TfidfVectorizer(lowercase=True, ngram_range=ngrams)\n",
    "        tfidf_tr = tfidfvec.fit_transform(data[i_tr])\n",
    "        tmp.fit(tfidf_tr, labels[i_tr])\n",
    "        qual_train.append(accuracy_score(tmp.predict(tfidf_tr), labels[i_tr]))\n",
    "        qual_valid.append(accuracy_score(tmp.predict(tfidfvec.transform(data[i_tst])), labels[i_tst]))\n",
    "        \n",
    "        #print('-train indexes:', i_tr,\n",
    "        #      '-validation indexes: ', i_tst, \n",
    "        #      '-train accuracy score: ', qual_train[-1],\n",
    "        #      '-validation accuracy score: ', qual_valid[-1], sep='\\n')\n",
    "        #print()\n",
    "        \n",
    "    return np.mean(qual_train), np.mean(qual_valid)\n",
    "\n",
    "def plotting(train, valid, param, model_name):\n",
    "    fig1 = plt.figure(figsize=(8,8))\n",
    "    ax1 = plt.subplot()\n",
    "    ax1.plot(param, train, label='Train')\n",
    "    ax2 = plt.subplot()\n",
    "    ax2.plot(param, valid, label='Validation')\n",
    "    plt.legend(loc=1, ncol=1)\n",
    "    plt.xlabel('Parameter')\n",
    "    plt.ylabel('Quality')\n",
    "    plt.title(model_name)\n",
    "\n",
    "def time_measure(model, data, labels, ii):\n",
    "    print('--->{}\\n fitting time:'.format(model))\n",
    "    %timeit model.fit(data, labels)\n",
    "    print('prediction time:')\n",
    "    %timeit model.predict(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAIN_KFOLD------------------\n",
      "ngrams - (1, 1)\n",
      "n-neigbours - 21.0\n",
      "result validation - 0.7142857142857142\n",
      "result train - 0.7142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobrg/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 1400]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-d90352f38135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m          )\n\u001b[1;32m     21\u001b[0m     \u001b[0mknc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mknc_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknc_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     print('------------------TRAIN+TEST------------------',\n",
      "\u001b[0;32m/home/bobrg/anaconda3/lib/python3.5/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \"\"\"\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bobrg/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bobrg/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 1400]"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHwCAYAAAChTMYRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6d33d69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KNearestNeighbors\n",
    "qual = np.zeros((len(ns), 3))\n",
    "for ngr in range(1, 3):\n",
    "    j = 0\n",
    "    ngrams = (ngr,ngr)\n",
    "    for i in ns:\n",
    "        knc_ = KNeighborsClassifier(n_neighbors=i)\n",
    "        qual[j][0], qual[j][1] = hyperparams_info(knc_, np.asarray(X_train), np.asarray(labels), ngrams)\n",
    "        qual[j][2] = i\n",
    "        j += 1\n",
    "    plotting([k[0] for k in qual], [k[1] for k in qual], ns, 'KNN')\n",
    "        \n",
    "    tmp = max(qual, key=lambda a: a[1])\n",
    "    print('------------------TRAIN_KFOLD------------------',\n",
    "          'ngrams - {}'.format(ngrams),\n",
    "          'n-neigbours - {}'.format(tmp[-1]),\n",
    "          'result validation - {}'.format(tmp[1]),\n",
    "          'result train - {}'.format(tmp[0]),\n",
    "          sep = '\\n'\n",
    "         )\n",
    "    knc_ = KNeighborsClassifier(n_neighbors=tmp[-1])\n",
    "    knc_.fit(X_train, y_train)\n",
    "    y_pred = knc_.predict(X_test)\n",
    "    print('------------------TRAIN+TEST------------------',\n",
    "          'n-neigbours - {}'.format(tmp[-1]),\n",
    "          'Result: {}'.format(accuracy_score(y_test, y_pred))\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При одном соседе модель просто выучила обучающую выборку и очень плохо отработала на валидации, что и ожидаемо.\n",
    "Начиная с 61 соседа качество не менялось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAIN_KFOLD------------------\n",
      "ngrams - (1, 1)\n",
      "C - 0.01\n",
      "result validation - 0.7142857142857142\n",
      "result train - 0.7142857142857143\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'an energetic   visually stunning   but intellectually hollow recreation of the mysterious life of jeanne d arc    in history jeanne d arc is lost in an ocean of mystery and controversy   which creates the perfect launching pad for talented and creative directors   who can basically alter the story as they wish    she came in a time where people desperately needed a saint    a hero that could rescue them for misery and deliver peace and happiness    director writer luc besson    nikita     leon    portrays his version of the peasant girl who commanded the armies of france and was burned at the stake for witchcraft    besson tries to recreate the person behind the legend    he tries not to show her as a saint or a villain    he shows her as a human being    in a time where blood was almost pouring from the sky   and the air smelled of rotten flesh   it is hard to keep your sanity    the only support and hope is in god    at the age of 13   jeanne   milla jovovich   watches her own sister murdered and raped by the english soldiers    this terrible event makes a lasting impact on jeanne s mind    god is no longer her support    he has become her obsession    she starts seeing visions and signs that command her to raise an army and free france from the siege of the english tyranny    with the help of the wise yolande d aragon   faye dunaway   and charles vii   john malcovich     whose grand royal ambitions and life are at stake   jeanne raises an army and marches towards the english walls    after this the film stays mostly on the battlefield   where besson demonstrates his ability to direct amazing action sequences   only occasionally resorting to a calmer tempo    the movie is filled with dreamy   symbolic images of pure artistic craftsmanship   that create a surreal and occasionally paranoiac atmosphere    the film is lost in time and space   hysterically jumping back and forth in jeanne s thoughts   imagination and conscience    besson s visual style permits the audience to enter the medieval age   feel the smell of fresh blood and the adrenaline pumping in your body in the heat of battle    but the film is far from being flawless    the script needs a lot of polishing    except for jeanne   there are no real characters    and although a grand star cast is assembled   their characters are nothing more than props   not more alive than the costumes that they are wearing    as for the maiden of lorraine herself   she is portrayed as a simple girl   too small for her divine task    in the latter part of the film   we see her as hysterical   confused and on the brink of madness   with her past purity and innocence for ever lost    jovovich handles the part with more panache than one might expect    but though her screen time is incredible excessive   both malcovich    being john malcovich    and dunaway    titus    surpass her rather overacted and simply unprofessional performance    and even hoffman manages to breathe some life into his dreadfully small part    besides casting jovovich   besson s only mistake is his extreme sense of patriotism that in the end ruins his so gloriously crafted painting    there are some viscously evil englishmen that murder   pillage and betray with a smile on their faces    and some incredibly brave and noble frenchmen   represented by the   three musketeers   of this story    the brave gilles de rais   vincent cassel     the wise aulon   desmond harrington   and the strong la hire   richard ridings      though all those actor perform well   their characters are nothing more than symbols    banners that proclaim the glory of france    and thus   there is no sense of realism in this film     the messenger  has muscles instead of brains    there is some relief in the end   where besson lays down his armor and starts thinking    dustin hoffman s appearance helps and the film ends elegantly and surprisingly effective with a climax worthy of praise    jeanne s character is unlocked   but whether god was in the picture or not   is never quite explained    was she a confused peasant girl driven by her own hunger for revenge    or was she truly a messenger of god    the film poses as many questions as answers and nothing is completely obvious    bess o messenger  is nothing more than a fairly good film    it is not much that you remember of it after you leave the theater    maybe the sound   the dreamy sequences   but certainly not the dialogue    it is an elegant and adrenaline pumping history lesson for the mtv generation   that although presents some interesting material   works better when it s on the battlefield    '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-6e1230bfea4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     knc_ = LogisticRegression(penalty='l2', fit_intercept=True, max_iter=100,\n\u001b[1;32m     23\u001b[0m                           C=tmp[-1], solver=\"lbfgs\", random_state=12345)\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mknc_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknc_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     print('------------------TRAIN+TEST------------------',\n",
      "\u001b[0;32m/home/bobrg/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[0;32m-> 1173\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bobrg/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/home/bobrg/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'an energetic   visually stunning   but intellectually hollow recreation of the mysterious life of jeanne d arc    in history jeanne d arc is lost in an ocean of mystery and controversy   which creates the perfect launching pad for talented and creative directors   who can basically alter the story as they wish    she came in a time where people desperately needed a saint    a hero that could rescue them for misery and deliver peace and happiness    director writer luc besson    nikita     leon    portrays his version of the peasant girl who commanded the armies of france and was burned at the stake for witchcraft    besson tries to recreate the person behind the legend    he tries not to show her as a saint or a villain    he shows her as a human being    in a time where blood was almost pouring from the sky   and the air smelled of rotten flesh   it is hard to keep your sanity    the only support and hope is in god    at the age of 13   jeanne   milla jovovich   watches her own sister murdered and raped by the english soldiers    this terrible event makes a lasting impact on jeanne s mind    god is no longer her support    he has become her obsession    she starts seeing visions and signs that command her to raise an army and free france from the siege of the english tyranny    with the help of the wise yolande d aragon   faye dunaway   and charles vii   john malcovich     whose grand royal ambitions and life are at stake   jeanne raises an army and marches towards the english walls    after this the film stays mostly on the battlefield   where besson demonstrates his ability to direct amazing action sequences   only occasionally resorting to a calmer tempo    the movie is filled with dreamy   symbolic images of pure artistic craftsmanship   that create a surreal and occasionally paranoiac atmosphere    the film is lost in time and space   hysterically jumping back and forth in jeanne s thoughts   imagination and conscience    besson s visual style permits the audience to enter the medieval age   feel the smell of fresh blood and the adrenaline pumping in your body in the heat of battle    but the film is far from being flawless    the script needs a lot of polishing    except for jeanne   there are no real characters    and although a grand star cast is assembled   their characters are nothing more than props   not more alive than the costumes that they are wearing    as for the maiden of lorraine herself   she is portrayed as a simple girl   too small for her divine task    in the latter part of the film   we see her as hysterical   confused and on the brink of madness   with her past purity and innocence for ever lost    jovovich handles the part with more panache than one might expect    but though her screen time is incredible excessive   both malcovich    being john malcovich    and dunaway    titus    surpass her rather overacted and simply unprofessional performance    and even hoffman manages to breathe some life into his dreadfully small part    besides casting jovovich   besson s only mistake is his extreme sense of patriotism that in the end ruins his so gloriously crafted painting    there are some viscously evil englishmen that murder   pillage and betray with a smile on their faces    and some incredibly brave and noble frenchmen   represented by the   three musketeers   of this story    the brave gilles de rais   vincent cassel     the wise aulon   desmond harrington   and the strong la hire   richard ridings      though all those actor perform well   their characters are nothing more than symbols    banners that proclaim the glory of france    and thus   there is no sense of realism in this film     the messenger  has muscles instead of brains    there is some relief in the end   where besson lays down his armor and starts thinking    dustin hoffman s appearance helps and the film ends elegantly and surprisingly effective with a climax worthy of praise    jeanne s character is unlocked   but whether god was in the picture or not   is never quite explained    was she a confused peasant girl driven by her own hunger for revenge    or was she truly a messenger of god    the film poses as many questions as answers and nothing is completely obvious    bess o messenger  is nothing more than a fairly good film    it is not much that you remember of it after you leave the theater    maybe the sound   the dreamy sequences   but certainly not the dialogue    it is an elegant and adrenaline pumping history lesson for the mtv generation   that although presents some interesting material   works better when it s on the battlefield    '"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHwCAYAAAChTMYRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6e7810be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "qual = np.zeros((len(ns), 3))\n",
    "for ngr in range(1, 3):\n",
    "    j = 0\n",
    "    ngrams = (ngr,ngr)\n",
    "    for i in cs:\n",
    "        logr_ = LogisticRegression(penalty='l2', fit_intercept=True, max_iter=100,\n",
    "                          C=i, solver=\"lbfgs\", random_state=12345)\n",
    "        qual[j][0], qual[j][1] = hyperparams_info(logr_, np.asarray(X_train), np.asarray(labels), ngrams)\n",
    "        qual[j][2] = i\n",
    "        j += 1\n",
    "    plotting([k[0] for k in qual], [k[1] for k in qual], cs, 'LogisticRegression')\n",
    "        \n",
    "    tmp = max(qual, key=lambda a: a[1])\n",
    "    print('------------------TRAIN_KFOLD------------------',\n",
    "          'ngrams - {}'.format(ngrams),\n",
    "          'C - {}'.format(tmp[-1]),\n",
    "          'result validation - {}'.format(tmp[1]),\n",
    "          'result train - {}'.format(tmp[0]),\n",
    "          sep = '\\n'\n",
    "         )\n",
    "    knc_ = LogisticRegression(penalty='l2', fit_intercept=True, max_iter=100,\n",
    "                          C=tmp[-1], solver=\"lbfgs\", random_state=12345)\n",
    "    knc_.fit(X_train, y_train)\n",
    "    y_pred = knc_.predict(X_test)\n",
    "    print('------------------TRAIN+TEST------------------',\n",
    "          'C - {}'.format(tmp[-1]),\n",
    "          'Result: {}'.format(accuracy_score(y_test, y_pred))\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MNB alpha= 0.0001\n",
      "---------------------result---------------------\n",
      "-mean train:  0.9995\n",
      "-mean validation:  0.74\n",
      "\n",
      "MNB alpha= 0.000517947467923\n",
      "---------------------result---------------------\n",
      "-mean train:  0.999333333333\n",
      "-mean validation:  0.75\n",
      "\n",
      "MNB alpha= 0.00268269579528\n",
      "---------------------result---------------------\n",
      "-mean train:  0.999\n",
      "-mean validation:  0.7635\n",
      "\n",
      "MNB alpha= 0.0138949549437\n",
      "---------------------result---------------------\n",
      "-mean train:  0.997333333333\n",
      "-mean validation:  0.7755\n",
      "\n",
      "MNB alpha= 0.0719685673001\n",
      "---------------------result---------------------\n",
      "-mean train:  0.990833333333\n",
      "-mean validation:  0.7915\n",
      "\n",
      "MNB alpha= 0.372759372031\n",
      "---------------------result---------------------\n",
      "-mean train:  0.977166666667\n",
      "-mean validation:  0.8095\n",
      "\n",
      "MNB alpha= 1.93069772888\n",
      "---------------------result---------------------\n",
      "-mean train:  0.941\n",
      "-mean validation:  0.78\n",
      "\n",
      "MNB alpha= 10.0\n",
      "---------------------result---------------------\n",
      "-mean train:  0.842\n",
      "-mean validation:  0.6975\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB\n",
    "qual = np.zeros((len(ns), 3))\n",
    "for ngr in range(1, 3):\n",
    "    j = 0\n",
    "    ngrams = (ngr,ngr)\n",
    "    for i in alphas:\n",
    "        mnb_ = MultinomialNB(alpha=i)\n",
    "        qual[j][0], qual[j][1] = hyperparams_info(mnb_, np.asarray(X_train), np.asarray(labels), ngrams)\n",
    "        qual[j][2] = i\n",
    "        j += 1\n",
    "    plotting([k[0] for k in qual], [k[1] for k in qual], alphas, 'MultinomialNB')\n",
    "        \n",
    "    tmp = max(qual, key=lambda a: a[1])\n",
    "    print('------------------TRAIN_KFOLD------------------',\n",
    "          'ngrams - {}'.format(ngrams),\n",
    "          'alpha - {}'.format(tmp[-1]),\n",
    "          'result validation - {}'.format(tmp[1]),\n",
    "          'result train - {}'.format(tmp[0]),\n",
    "          sep = '\\n'\n",
    "         )\n",
    "    knc_ = MultinomialNB(alpha=tmp[-1])\n",
    "    knc_.fit(X_train, y_train)\n",
    "    y_pred = knc_.predict(X_test)\n",
    "    print('------------------TRAIN+TEST------------------',\n",
    "          'alpha - {}'.format(tmp[-1]),\n",
    "          'Result: {}'.format(accuracy_score(y_test, y_pred))\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams = 2\n",
    "[some info about choosing n-grams and cv](https://stats.stackexchange.com/questions/155483/estimating-the-best-length-of-n-gram) <br> </br>\n",
    "*что означает n-gram=2?* <br> </br>\n",
    "если n-gram=1 будет считать вероятность встретить определенное слово, то n-gram=2 будет парсить строку на посл-ти из двух слов.\n",
    "(перекрест в одно слово: … to be or not to be …\t=> …, to be, be or, or not, not to, to be, …)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 4. (опционально)\n",
    "#### Исследование влияния количества признаков FeatureHasher на качество классификации (+3 балла к сумме по всем ДЗ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Изучите, что такое feature hashing (достаточно разобаться с документацией sklearn) и кратко опишите. Как будет меняться качество классификации для обозначенных ранее методов при использовании FeatureHasher (или HashingVectorizer) из пакета sklearn перед TF-IDF преобразованием, если</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = np.logspace(1, 5, 5, base=10) # количество признаков\n",
    "non_negative=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>В этом задании можно воспользоваться GridSearchCV</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Задача 5. (опционально)\n",
    "__Простой прототип (+ 2 балла к сумме по всем ДЗ)__\n",
    "\n",
    "Напишите функцию, которая берет на вход произвольную строку и возвращает для нее предсказание для вашей задачи. Придумайте по 3 примера строк для положительного и отрицательного класса, сделайте для них предсказание. Совпадают ли ваши метки и предсказания классификатора? Оцените (любым способом), насколько придуманные вами тексты похожи на объекты датасета, с которым вы работали.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_class_for_text(s):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
