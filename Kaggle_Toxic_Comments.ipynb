{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "#for text-preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack, coo_matrix\n",
    "#hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "#stacking\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('toxic_train.csv')\n",
    "test = pd.read_csv('toxic_train.csv')\n",
    "labels = pd.read_csv('labels_tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_text(s):\n",
    "    s = s.replace(':)', 'smile')\n",
    "    s = s.replace(':D', 'laugh')\n",
    "    # Removes all characters from string except letters and digits and convert letters to lowercase\n",
    "    s = re.sub(\"[^a-zA-Z0-9]\", \" \", s.lower())\n",
    "    # Remove new lines\n",
    "    s = re.sub(\"\\\\n\",\"\", s)\n",
    "    # Change urls\n",
    "    s = re.sub(\"[a-zA-Z0-9]*(https://)[a-zA-Z0-9.]*\", \"url\", s)\n",
    "    # Remove IPs\n",
    "    s = re.sub(\"\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}\",\"\", s)\n",
    "    # Remove usernames\n",
    "    s = re.sub(\"\\[\\[.*\\]\",\"\", s)\n",
    "    # Remove numbers\n",
    "    s = re.sub(\"\\\\b[0-9]+\\\\b\", \"\", s)\n",
    "    # better use (\\w+[0-9])\n",
    "    # fix grammar\n",
    "    s = re.sub('\\\\bf{1,}[a-z]*(ck)\\\\b', 'fuck', s)\n",
    "    # find cock symb lol\n",
    "    s = re.sub('8={1,}D?', 'cock', s)\n",
    "\n",
    "    #formalize text\n",
    "    s = s.replace(\"don\\'t\", \"do not\")\n",
    "    s = s.replace(\"doesn\\'t\", \"does not\")\n",
    "    s = s.replace(\"didn\\'t\", \"did not\")\n",
    "    s = s.replace(\"won\\'t\", \"will not\")\n",
    "    s = s.replace(\"haven\\'t\", \"have not\")\n",
    "    s = s.replace('haven\\\\\\'t', 'have not')\n",
    "    #s = s.replace('\\'ll', ' will')\n",
    "    #clean text\n",
    "    s = s.replace('\\\\', ' ')\n",
    "    s = s.replace('\\n', '')\n",
    "    s = s.replace(\"'s\", ' is')\n",
    "    s = s.replace('“', '')\n",
    "    s = s.replace('fck', 'fuck')\n",
    "    s = s.replace('wtf', 'what the fuck')\n",
    "    s = s.replace('cockwad', 'idiot')\n",
    "    s = s.replace('скоморохъ', 'buffoon')\n",
    "    s = s.replace('backash', 'backlash')\n",
    "    s = s.replace('bizarrethere', 'bizarre there')\n",
    "    s = s.replace('backash', 'backlash')\n",
    "    s = s.replace('dummasses', 'dumbass')\n",
    "    s = s.replace('lesbianswomen', 'lesbian women')\n",
    "    s = s.replace('bisexualis', 'bisexual')\n",
    "    s = s.replace('sexualitypenis','sexuality penis')\n",
    "    s = s.replace('dorkgasm', 'orgasm')\n",
    "    s = s.replace('cockmy', 'cock my')\n",
    "    s = s.replace('supertroll', 'super troll')\n",
    "    s = s.replace('faggotttttttt', 'faggot')\n",
    "    s = s.replace('sucks50', 'sucks 50')\n",
    "    s = s.replace('themfuck', 'them fuck')\n",
    "    s = s.replace('offenderfugitive', 'offender fugitive')\n",
    "    s = s.replace('creationisrael', 'creation israel')\n",
    "    s = s.replace('assholestating', 'asshole stating')\n",
    "    s = s.replace('idiotenough', 'idiot enough')\n",
    "    s = s.replace('lessblunt', 'less blunt')\n",
    "    s = s.replace('anticanadian', 'anti canadian')\n",
    "    s = s.replace('afrikanblack', 'african black')\n",
    "    s = s.replace('againbitch', 'again bitch')\n",
    "    s = s.replace('animalfucker', 'animal fucker')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.comment_text = train.comment_text.apply(beautify_text)\n",
    "test.comment_text = test.comment_text.apply(beautify_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = [i[:-1] for i in open('negative-words.txt')]\n",
    "\n",
    "symbs = ['!', '@', '#', '$', '%', '^', '&', '(', '*', '№', '=', '-', '+', '<', '>']\n",
    "punct = ['.', ',', '\\'', ';', ':']\n",
    "smailes = [':)', ':D', ')']\n",
    "neg_phrases = ['fuck you', 'screw you', 'kill you', 'beat you', 'die you', 'damn it', 'damn you', 'bitchin out', 'duck face', 'heil hitler' ]\n",
    "short_phrases = ['wtf', 'dgaf', 'fml', 'foad', 'ftw', 'milf']\n",
    "races_and_orients = ['lesbian', 'gay', 'homo', 'bromance', 'dyke', 'lesbo', 'lezzie', 'faggot', 'nigga', 'nigger', 'jew', 'yankee', 'racist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words_counts = train_data.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in neg_words]))\n",
    "\n",
    "symbols_count = train.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in symbs]))\n",
    "\n",
    "punct_count = train.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in punct]))\n",
    "\n",
    "smailes_count = train.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in smailes]))\n",
    "\n",
    "len_of_comment = train.comment_text.apply(lambda a: len(a))\n",
    "\n",
    "capital_letters = train.comment_text.apply(lambda a: len([i for i in a if i.isupper()]))\n",
    "\n",
    "neg_phrases_count = train.comment_text.apply(lambda a: len([i for i in neg_phrases if i in a]))\n",
    "\n",
    "short_phrases_count = train.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in short_phrases]))\n",
    "\n",
    "races_and_orients_count = train.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in races_and_orients]))\n",
    "\n",
    "count_spaces = train.comment_text.apply(lambda a: len([i for i in a if i == ' ']))\n",
    "\n",
    "count_ips = train.comment_text.apply(lambda a: len(re.findall(\"\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}\", a)))\n",
    "\n",
    "train = train.assign(capital_letters=capital_letters,\n",
    "                     len_of_comment=len_of_comment,\n",
    "                     count_ips=count_ips,\n",
    "                     count_spaces=count_spaces,\n",
    "                     sybs = symbols_count,\n",
    "                     smailes = smailes_count,\n",
    "                     neg_words=neg_words_counts,\n",
    "                    neg_phrases=neg_phrases_count,\n",
    "                    short_phrases=short_phrases_count,\n",
    "                    races_and_orients=races_and_orients_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words_counts_ts = test.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in neg_words]))\n",
    "\n",
    "capital_letters_ts = test.comment_text.apply(lambda a: len([i for i in a if i.isupper()]))\n",
    "len_of_comment_ts = test.comment_text.apply(lambda a: len(a))\n",
    "count_spaces_ts = test.comment_text.apply(lambda a: len([i for i in a if i == ' ']))\n",
    "count_ips_ts = test.comment_text.apply(lambda a: len(re.findall(\"\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}\", a)))\n",
    "punct_count_ts = test.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in punct]))\n",
    "symbols_count_ts = test.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in symbs]))\n",
    "smailes_count_ts = test.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in smailes]))\n",
    "neg_phrases_count_ts = test.comment_text.apply(lambda a: len([i for i in neg_phrases if i in a]))\n",
    "short_phrases_count_ts = test.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in short_phrases]))\n",
    "races_and_orients_count_ts = test.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in races_and_orients]))\n",
    "\n",
    "test = test.assign(capital_letters=capital_letters_ts,\n",
    "                     len_of_comment=len_of_comment_ts,\n",
    "                     count_ips=count_ips_ts,\n",
    "                     count_spaces=count_spaces_ts,\n",
    "                     sybs = symbols_count_ts,\n",
    "                     smailes = smailes_count_ts,\n",
    "                     neg_words=neg_words_counts_ts,\n",
    "                    neg_phrases=neg_phrases_count_ts,\n",
    "                    short_phrases=short_phrases_count_ts,\n",
    "                    races_and_orients=races_and_orients_count_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>capital_letters</th>\n",
       "      <th>count_ips</th>\n",
       "      <th>count_spaces</th>\n",
       "      <th>len_of_comment</th>\n",
       "      <th>neg_phrases</th>\n",
       "      <th>neg_words</th>\n",
       "      <th>races_and_orients</th>\n",
       "      <th>short_phrases</th>\n",
       "      <th>smailes</th>\n",
       "      <th>sybs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>622</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  0000997932d777bf  explanation why the edits made under my userna...   \n",
       "1  000103f0d9cfb60f  d aww  he matches this background colour i m s...   \n",
       "2  000113f07ec002fd  hey man  i m really not trying to edit war  it...   \n",
       "3  0001b41b1c6bb37e    more i can t make any real suggestions on im...   \n",
       "4  0001d958c54c6e35  you  sir  are my hero  any chance you remember...   \n",
       "\n",
       "   capital_letters  count_ips  count_spaces  len_of_comment  neg_phrases  \\\n",
       "0                0          0            49             252            0   \n",
       "1                0          0            29             102            0   \n",
       "2                0          0            47             233            0   \n",
       "3                0          0           136             622            0   \n",
       "4                0          0            17              67            0   \n",
       "\n",
       "   neg_words  races_and_orients  short_phrases  smailes  sybs  \n",
       "0          0                  0              0        0     0  \n",
       "1          1                  0              0        0     0  \n",
       "2          0                  0              0        0     0  \n",
       "3          1                  0              0        0     0  \n",
       "4          0                  0              0        0     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('toxic_train.csv')\n",
    "test = pd.read_csv('toxic_test.csv')\n",
    "labels = pd.read_csv('labels_tr')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0              0\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = ['capital_letters', 'len_of_comment', 'count_ips', 'count_spaces', 'sybs', 'smailes', 'neg_words', 'neg_phrases', 'short_phrases', 'races_and_orients']\n",
    "classes_ = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train_ids = train[['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=50,  max_features=30000, \n",
    "            analyzer='char',ngram_range=(1,3))\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "\n",
    "tfv.fit(all_text)\n",
    "train_text = tfv.transform(train.comment_text)\n",
    "test_text = tfv.transform(test.comment_text)\n",
    "\n",
    "tfv = TfidfVectorizer(min_df=50,  max_features=30000, \n",
    "            analyzer='word',ngram_range=(1,3))\n",
    "tfv.fit(all_text)\n",
    "train_text = hstack((train_text, tfv.transform(train.comment_text)))\n",
    "test_text = hstack((test_text, tfv.transform(test.comment_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 39567)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/novikov/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# train_text_ = train_text.todense()\n",
    "# test_text_ = test_text.todense()\n",
    "for i in extra_features:\n",
    "    mms = MinMaxScaler()\n",
    "    train_text = hstack((train_text, coo_matrix(mms.fit_transform(train[i].values.reshape(-1, 1)))))\n",
    "    test_text = hstack((test_text, coo_matrix(mms.transform(test[i].values.reshape(-1, 1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 39577)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['toxic'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_text.tocsr()\n",
    "test_text = test_text.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_svc(params):\n",
    "    model = SVC(kernel=params['kernel'], max_iter=10)\n",
    "    \n",
    "    shuffle = KFold()\n",
    "    score = cross_val_score(model, X_train, y_train, cv=shuffle, scoring='roc_auc', n_jobs=1)\n",
    "    return 1-score.mean()\n",
    "\n",
    "X_train = train_text\n",
    "\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "                'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "linear\n",
      "rbf\n",
      "linear\n",
      "sigmoid\n",
      "rbf\n",
      "toxic best:\n",
      "{'kernel': 3}\n",
      "Fitting model...\n",
      "poly\n",
      "sigmoid\n",
      "rbf\n",
      "rbf\n",
      "linear\n",
      "severe_toxic best:\n",
      "{'kernel': 3}\n",
      "Fitting model...\n",
      "poly\n",
      "rbf\n",
      "linear\n",
      "linear\n",
      "sigmoid\n",
      "obscene best:\n",
      "{'kernel': 0}\n",
      "Fitting model...\n",
      "linear\n",
      "rbf\n",
      "sigmoid\n",
      "linear\n",
      "sigmoid\n",
      "threat best:\n",
      "{'kernel': 0}\n",
      "Fitting model...\n",
      "poly\n",
      "poly\n",
      "linear\n",
      "linear\n",
      "poly\n",
      "insult best:\n",
      "{'kernel': 1}\n",
      "Fitting model...\n",
      "poly\n",
      "sigmoid\n",
      "rbf\n",
      "rbf\n",
      "linear\n",
      "identity_hate best:\n",
      "{'kernel': 2}\n"
     ]
    }
   ],
   "source": [
    "best = []\n",
    "\n",
    "for i in range(len(classes_)):\n",
    "    y_train = labels.values[:, i]\n",
    "    print('Fitting model...')\n",
    "    best = fmin(objective_svc,\n",
    "                param_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=5)\n",
    "    print(classes_[i], 'best:')\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```best_svm = space_eval(param_space, best)\n",
    "print('Best paramns for svm:', best_svm)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(params):\n",
    "    params = {\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "    }\n",
    "    \n",
    "    model = lgbm.LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        tree_method='gpu_hist',\n",
    "        predictor='gpu_predictor',\n",
    "        **params\n",
    "    )\n",
    "    print(model)\n",
    "    shuffle = KFold()\n",
    "    score = cross_val_score(model, X_train, y_train, cv=shuffle, scoring='roc_auc', n_jobs=1)\n",
    "    return 1-score.mean()\n",
    "\n",
    "X_train = train_text\n",
    "\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "LGBMClassifier(boosting_type='gbdt', colsample_bytree='0.842',\n",
      "        learning_rate=0.01, max_bin=255, max_depth=-1,\n",
      "        min_child_samples=10, min_child_weight=5, min_split_gain=0.0,\n",
      "        n_estimators=500, n_jobs=-1, num_leaves=54, objective=None,\n",
      "        predictor='gpu_predictor', random_state=0, reg_alpha=0.0,\n",
      "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=50000, subsample_freq=1, tree_method='gpu_hist')\n",
      "LGBMClassifier(boosting_type='gbdt', colsample_bytree='0.672',\n",
      "        learning_rate=0.01, max_bin=255, max_depth=-1,\n",
      "        min_child_samples=10, min_child_weight=5, min_split_gain=0.0,\n",
      "        n_estimators=500, n_jobs=-1, num_leaves=36, objective=None,\n",
      "        predictor='gpu_predictor', random_state=0, reg_alpha=0.0,\n",
      "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=50000, subsample_freq=1, tree_method='gpu_hist')\n",
      "LGBMClassifier(boosting_type='gbdt', colsample_bytree='0.564',\n",
      "        learning_rate=0.01, max_bin=255, max_depth=-1,\n",
      "        min_child_samples=10, min_child_weight=5, min_split_gain=0.0,\n",
      "        n_estimators=500, n_jobs=-1, num_leaves=62, objective=None,\n",
      "        predictor='gpu_predictor', random_state=0, reg_alpha=0.0,\n",
      "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=50000, subsample_freq=1, tree_method='gpu_hist')\n",
      "LGBMClassifier(boosting_type='gbdt', colsample_bytree='0.574',\n",
      "        learning_rate=0.01, max_bin=255, max_depth=-1,\n",
      "        min_child_samples=10, min_child_weight=5, min_split_gain=0.0,\n",
      "        n_estimators=500, n_jobs=-1, num_leaves=46, objective=None,\n",
      "        predictor='gpu_predictor', random_state=0, reg_alpha=0.0,\n",
      "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=50000, subsample_freq=1, tree_method='gpu_hist')\n",
      "toxic best:\n",
      "{'colsample_bytree': 0.564246261338949, 'num_leaves': 62.0}\n",
      "Fitting model...\n",
      "severe_toxic best:\n",
      "{'colsample_bytree': 0.564246261338949, 'num_leaves': 62.0}\n",
      "Fitting model...\n",
      "obscene best:\n",
      "{'colsample_bytree': 0.564246261338949, 'num_leaves': 62.0}\n",
      "Fitting model...\n",
      "threat best:\n",
      "{'colsample_bytree': 0.564246261338949, 'num_leaves': 62.0}\n",
      "Fitting model...\n",
      "insult best:\n",
      "{'colsample_bytree': 0.564246261338949, 'num_leaves': 62.0}\n",
      "Fitting model...\n",
      "identity_hate best:\n",
      "{'colsample_bytree': 0.564246261338949, 'num_leaves': 62.0}\n"
     ]
    }
   ],
   "source": [
    "model = lgbm.LGBMClassifier()\n",
    "param_space = {\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "}\n",
    "\n",
    "for i in range(len(classes_)):\n",
    "    y_train = labels.values[:, i]\n",
    "    print('Fitting model...')\n",
    "    best = fmin(objective_lgbm,\n",
    "                param_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=4,\n",
    "                trials=trials)\n",
    "    print(classes_[i], 'best:')\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbm = {'colsample_bytree': 0.564246261338949, 'num_leaves': 62}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOF algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_text\n",
    "X_test = test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_1(model, folds=10, classes_to_fit=classes_):\n",
    "    scores = []\n",
    "    scores_classes = np.zeros((len(classes_to_fit), folds))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    if (len(classes_to_fit)>1):\n",
    "        submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "        submission_oof =  pd.DataFrame.from_dict({'id': train['id']})\n",
    "    else:\n",
    "        submission = pd.DataFrame()\n",
    "        submission_oof =  pd.DataFrame()\n",
    "    for j, (class_name) in enumerate(classes_to_fit):\n",
    "        print('Picking a class...')\n",
    "        \n",
    "        classifier = model\n",
    "\n",
    "        test_pred = np.zeros(X_test.shape[0])\n",
    "        train_pred = np.zeros(labels[class_name].shape[0])\n",
    "\n",
    "        \n",
    "        for i, (train_index, val_index) in enumerate(skf.split(X_train, labels[class_name].values)):\n",
    "           \n",
    "            fold_train, fold_val = X_train[train_index], X_train[val_index]\n",
    "            y_train, y_val = labels.loc[train_index], labels.loc[val_index]\n",
    "            print('Fitting model...')\n",
    "            classifier.fit(fold_train, y_train[class_name])\n",
    "            \n",
    "            train_pred[val_index] = classifier.predict_proba(fold_val)[:, 1]\n",
    "            test_pred += classifier.predict_proba(X_test)[:, 1]\n",
    "           \n",
    "            scores_classes[j][i] = roc_auc_score(y_val[class_name], train_pred[val_index])\n",
    "            \n",
    "            print('\\n Fold %02d class %s AUC: %.6f' % ((i+1), class_name, scores_classes[j][i]))\n",
    "            \n",
    "        train_oof_auc = roc_auc_score(labels[class_name], train_pred)\n",
    "        print('\\n Average class %s AUC:\\t%.6f' % (class_name, np.mean(scores_classes[j])))\n",
    "        print(' Out-of-fold class %s AUC (train):\\t%.6f' % (class_name, train_oof_auc))\n",
    "        \n",
    "        submission[class_name] = test_pred / folds\n",
    "        submission_oof['prediction_' + class_name] = train_pred\n",
    "        \n",
    "    return submission_oof, submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class toxic AUC: 0.440339\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class toxic AUC: 0.671019\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class toxic AUC: 0.504968\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class toxic AUC: 0.500440\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class toxic AUC: 0.616368\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class toxic AUC: 0.759078\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class toxic AUC: 0.479310\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class toxic AUC: 0.482598\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class toxic AUC: 0.645885\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class toxic AUC: 0.543730\n",
      "\n",
      " Average class toxic AUC:\t0.564374\n",
      " Out-of-fold class toxic AUC (train):\t0.542519\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class severe_toxic AUC: 0.335931\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class severe_toxic AUC: 0.554124\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class severe_toxic AUC: 0.719803\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class severe_toxic AUC: 0.770820\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class severe_toxic AUC: 0.285404\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class severe_toxic AUC: 0.923251\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class severe_toxic AUC: 0.620531\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class severe_toxic AUC: 0.806489\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class severe_toxic AUC: 0.494281\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class severe_toxic AUC: 0.313567\n",
      "\n",
      " Average class severe_toxic AUC:\t0.582420\n",
      " Out-of-fold class severe_toxic AUC (train):\t0.553786\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class obscene AUC: 0.543548\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class obscene AUC: 0.779941\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class obscene AUC: 0.701421\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class obscene AUC: 0.526889\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class obscene AUC: 0.743928\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class obscene AUC: 0.632348\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class obscene AUC: 0.604810\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class obscene AUC: 0.832309\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class obscene AUC: 0.734366\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class obscene AUC: 0.476957\n",
      "\n",
      " Average class obscene AUC:\t0.657652\n",
      " Out-of-fold class obscene AUC (train):\t0.565615\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class threat AUC: 0.791317\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class threat AUC: 0.610071\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class threat AUC: 0.646678\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class threat AUC: 0.600813\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class threat AUC: 0.580018\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class threat AUC: 0.529616\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class threat AUC: 0.759196\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class threat AUC: 0.582063\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class threat AUC: 0.692953\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class threat AUC: 0.596330\n",
      "\n",
      " Average class threat AUC:\t0.638906\n",
      " Out-of-fold class threat AUC (train):\t0.596171\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class insult AUC: 0.434079\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class insult AUC: 0.383703\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class insult AUC: 0.432530\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class insult AUC: 0.338547\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class insult AUC: 0.343775\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class insult AUC: 0.579477\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class insult AUC: 0.438649\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class insult AUC: 0.434712\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class insult AUC: 0.385963\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class insult AUC: 0.486890\n",
      "\n",
      " Average class insult AUC:\t0.425833\n",
      " Out-of-fold class insult AUC (train):\t0.490601\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class identity_hate AUC: 0.358774\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class identity_hate AUC: 0.561576\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class identity_hate AUC: 0.572551\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class identity_hate AUC: 0.549508\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class identity_hate AUC: 0.521554\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class identity_hate AUC: 0.524016\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class identity_hate AUC: 0.495023\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class identity_hate AUC: 0.515893\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class identity_hate AUC: 0.465913\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class identity_hate AUC: 0.609853\n",
      "\n",
      " Average class identity_hate AUC:\t0.517466\n",
      " Out-of-fold class identity_hate AUC (train):\t0.496828\n"
     ]
    }
   ],
   "source": [
    "print('SVM')\n",
    "kernels = ['sigmoid', 'sigmoid', 'linear', 'linear', 'poly', 'rbf']\n",
    "test_svm = pd.DataFrame.from_dict({'id': test['id']})\n",
    "train_svm = pd.DataFrame.from_dict({'id': train['id']})\n",
    "\n",
    "train_svm[classes_[0]], test_svm[classes_[0]] = stacking_1(SVC(kernel=kernels[0], max_iter=10, probability=True), classes_to_fit=[classes_[0]])\n",
    "for i in range(1, len(classes_)):\n",
    "    train_svm[classes_[i]], test_svm[classes_[i]] = stacking_1(SVC(kernel=kernels[i], max_iter=10, probability=True), classes_to_fit=[classes_[i]])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svm.to_csv('train_svm.csv')\n",
    "test_svm.to_csv('test_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class toxic AUC: 0.961265\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class toxic AUC: 0.966141\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class toxic AUC: 0.965902\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class toxic AUC: 0.965012\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class toxic AUC: 0.965764\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class toxic AUC: 0.964430\n",
      "Fitting model...\n"
     ]
    }
   ],
   "source": [
    "print('GradientBoosting')\n",
    "train_lgbm, test_lgbm = stacking_1(lgbm.LGBMClassifier(n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        tree_method='gpu_hist',\n",
    "        predictor='gpu_predictor',\n",
    "        **best_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class toxic AUC: 0.974020\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class toxic AUC: 0.978608\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class toxic AUC: 0.974214\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class toxic AUC: 0.974892\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class toxic AUC: 0.976137\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class toxic AUC: 0.977330\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class toxic AUC: 0.973775\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class toxic AUC: 0.977807\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class toxic AUC: 0.977316\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class toxic AUC: 0.978905\n",
      "\n",
      " Average class toxic AUC:\t0.976300\n",
      " Out-of-fold class toxic AUC (train):\t0.976278\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class severe_toxic AUC: 0.986412\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class severe_toxic AUC: 0.987077\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class severe_toxic AUC: 0.989266\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class severe_toxic AUC: 0.988387\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class severe_toxic AUC: 0.991080\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class severe_toxic AUC: 0.989232\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class severe_toxic AUC: 0.986867\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class severe_toxic AUC: 0.987838\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class severe_toxic AUC: 0.983964\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class severe_toxic AUC: 0.989739\n",
      "\n",
      " Average class severe_toxic AUC:\t0.987986\n",
      " Out-of-fold class severe_toxic AUC (train):\t0.987964\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class obscene AUC: 0.991074\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class obscene AUC: 0.988913\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class obscene AUC: 0.988981\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class obscene AUC: 0.988987\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class obscene AUC: 0.987954\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class obscene AUC: 0.987818\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class obscene AUC: 0.987468\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class obscene AUC: 0.986583\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class obscene AUC: 0.986804\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class obscene AUC: 0.989600\n",
      "\n",
      " Average class obscene AUC:\t0.988418\n",
      " Out-of-fold class obscene AUC (train):\t0.988414\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class threat AUC: 0.989048\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class threat AUC: 0.975962\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class threat AUC: 0.987090\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class threat AUC: 0.996705\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class threat AUC: 0.991252\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class threat AUC: 0.976807\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class threat AUC: 0.981420\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class threat AUC: 0.993201\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class threat AUC: 0.981585\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class threat AUC: 0.987451\n",
      "\n",
      " Average class threat AUC:\t0.986052\n",
      " Out-of-fold class threat AUC (train):\t0.986006\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class insult AUC: 0.981155\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class insult AUC: 0.979325\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class insult AUC: 0.981212\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class insult AUC: 0.981664\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class insult AUC: 0.980755\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class insult AUC: 0.979939\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class insult AUC: 0.979753\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class insult AUC: 0.981244\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class insult AUC: 0.982730\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class insult AUC: 0.979205\n",
      "\n",
      " Average class insult AUC:\t0.980698\n",
      " Out-of-fold class insult AUC (train):\t0.980683\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class identity_hate AUC: 0.979354\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class identity_hate AUC: 0.976446\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class identity_hate AUC: 0.986511\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class identity_hate AUC: 0.979465\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class identity_hate AUC: 0.987207\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class identity_hate AUC: 0.978245\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class identity_hate AUC: 0.982156\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class identity_hate AUC: 0.979318\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class identity_hate AUC: 0.975357\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class identity_hate AUC: 0.978860\n",
      "\n",
      " Average class identity_hate AUC:\t0.980292\n",
      " Out-of-fold class identity_hate AUC (train):\t0.980273\n",
      "MultinomialNB\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class toxic AUC: 0.952210\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class toxic AUC: 0.954768\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class toxic AUC: 0.950652\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class toxic AUC: 0.951421\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class toxic AUC: 0.949930\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class toxic AUC: 0.953446\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class toxic AUC: 0.951010\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class toxic AUC: 0.953241\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class toxic AUC: 0.952797\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class toxic AUC: 0.955684\n",
      "\n",
      " Average class toxic AUC:\t0.952516\n",
      " Out-of-fold class toxic AUC (train):\t0.952498\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class severe_toxic AUC: 0.965066\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class severe_toxic AUC: 0.969908\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class severe_toxic AUC: 0.962931\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class severe_toxic AUC: 0.963592\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class severe_toxic AUC: 0.971484\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class severe_toxic AUC: 0.969320\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class severe_toxic AUC: 0.965703\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class severe_toxic AUC: 0.966639\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class severe_toxic AUC: 0.954074\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class severe_toxic AUC: 0.974468\n",
      "\n",
      " Average class severe_toxic AUC:\t0.966318\n",
      " Out-of-fold class severe_toxic AUC (train):\t0.966236\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class obscene AUC: 0.966128\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class obscene AUC: 0.957783\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class obscene AUC: 0.963959\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class obscene AUC: 0.966197\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class obscene AUC: 0.956886\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class obscene AUC: 0.956241\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class obscene AUC: 0.958574\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class obscene AUC: 0.960639\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class obscene AUC: 0.959909\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class obscene AUC: 0.965220\n",
      "\n",
      " Average class obscene AUC:\t0.961154\n",
      " Out-of-fold class obscene AUC (train):\t0.961153\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class threat AUC: 0.880900\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class threat AUC: 0.850369\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class threat AUC: 0.904508\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class threat AUC: 0.920937\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class threat AUC: 0.883593\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class threat AUC: 0.845259\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class threat AUC: 0.882387\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class threat AUC: 0.905393\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class threat AUC: 0.869113\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class threat AUC: 0.874705\n",
      "\n",
      " Average class threat AUC:\t0.881717\n",
      " Out-of-fold class threat AUC (train):\t0.881518\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class insult AUC: 0.959986\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class insult AUC: 0.960666\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class insult AUC: 0.956266\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class insult AUC: 0.958498\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class insult AUC: 0.959128\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class insult AUC: 0.958173\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class insult AUC: 0.957503\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class insult AUC: 0.959649\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class insult AUC: 0.961982\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class insult AUC: 0.962180\n",
      "\n",
      " Average class insult AUC:\t0.959403\n",
      " Out-of-fold class insult AUC (train):\t0.959389\n",
      "Picking a class...\n",
      "Fitting model...\n",
      "\n",
      " Fold 01 class identity_hate AUC: 0.902306\n",
      "Fitting model...\n",
      "\n",
      " Fold 02 class identity_hate AUC: 0.921254\n",
      "Fitting model...\n",
      "\n",
      " Fold 03 class identity_hate AUC: 0.916150\n",
      "Fitting model...\n",
      "\n",
      " Fold 04 class identity_hate AUC: 0.910464\n",
      "Fitting model...\n",
      "\n",
      " Fold 05 class identity_hate AUC: 0.938567\n",
      "Fitting model...\n",
      "\n",
      " Fold 06 class identity_hate AUC: 0.889867\n",
      "Fitting model...\n",
      "\n",
      " Fold 07 class identity_hate AUC: 0.914499\n",
      "Fitting model...\n",
      "\n",
      " Fold 08 class identity_hate AUC: 0.894770\n",
      "Fitting model...\n",
      "\n",
      " Fold 09 class identity_hate AUC: 0.906801\n",
      "Fitting model...\n",
      "\n",
      " Fold 10 class identity_hate AUC: 0.898173\n",
      "\n",
      " Average class identity_hate AUC:\t0.909285\n",
      " Out-of-fold class identity_hate AUC (train):\t0.909176\n"
     ]
    }
   ],
   "source": [
    "print('LogReg')\n",
    "train_lr, test_lr = stacking_1(LogisticRegression())\n",
    "print('MultinomialNB')\n",
    "train_mnb, test_mnb = stacking_1(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lr.to_csv('train_lr.csv')\n",
    "test_lr.to_csv('test_lr.csv')\n",
    "\n",
    "train_mnb.to_csv('train_mnb.csv')\n",
    "test_mnb.to_csv('test_mnb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
