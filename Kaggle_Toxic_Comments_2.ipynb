{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#for text-preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.preprocessing.text import one_hot, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#featureengineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#neuralnets\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Convolution1D, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.layers import SimpleRNN, LSTM, Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "#embedings\n",
    "import gensim\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95846</th>\n",
       "      <td>999977655955</td>\n",
       "      <td>\"\\nI have discussed it, unlike most of those w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95847</th>\n",
       "      <td>999982426659</td>\n",
       "      <td>ps. Almost forgot, Paine don't reply back to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95848</th>\n",
       "      <td>999982764066</td>\n",
       "      <td>Mamoun Darkazanli\\nFor some reason I am unable...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95849</th>\n",
       "      <td>999986890563</td>\n",
       "      <td>Salafi would be a better term. It is more poli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95850</th>\n",
       "      <td>999988164717</td>\n",
       "      <td>making wikipedia a better and more inviting pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "95846  999977655955  \"\\nI have discussed it, unlike most of those w...      0   \n",
       "95847  999982426659  ps. Almost forgot, Paine don't reply back to t...      1   \n",
       "95848  999982764066  Mamoun Darkazanli\\nFor some reason I am unable...      0   \n",
       "95849  999986890563  Salafi would be a better term. It is more poli...      0   \n",
       "95850  999988164717  making wikipedia a better and more inviting pl...      0   \n",
       "\n",
       "       severe_toxic  obscene  threat  insult  identity_hate  \n",
       "95846             0        0       0       0              0  \n",
       "95847             0        1       0       0              0  \n",
       "95848             0        0       0       0              0  \n",
       "95849             0        0       0       0              0  \n",
       "95850             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train nulls\n",
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n",
      "test nulls\n",
      "id              0\n",
      "comment_text    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print( 'train nulls',\n",
    "train.isnull().sum(),\n",
    "      'test nulls',\n",
    "test.isnull().sum(),\n",
    "sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.comment_text.fillna('unknown', inplace=True)\n",
    "test.comment_text.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes_ = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beautify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Amount of comments in ds')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAG5CAYAAAADNAT0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28bce987b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = train[classes_].sum(axis=1).unique()\n",
    "bins.sort()\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "plt.hist(train[classes_].sum(axis=1), bins)\n",
    "plt.title('Labels info_1')\n",
    "plt.xlabel('Amount of classes for comment')\n",
    "plt.ylabel('Amount of comments in ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            9237\n",
       "severe_toxic      965\n",
       "obscene          5109\n",
       "threat            305\n",
       "insult           4765\n",
       "identity_hate     814\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[classes_].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS TOXIC\n",
      "ps. Almost forgot, Paine don't reply back to this shit, I don't want to see/care what you have to say do your bitching out of my sight, plskthxbai.\n",
      "\n",
      "CLASS SEVERE_TOXIC\n",
      "98.248.32.178 I will set you on fire, I will shoot your ass up. I will cut your penis off and I will shove it down your throat and choke you. I will cut you up big time motherfucker.\n",
      "\n",
      "CLASS OBSCENE\n",
      "ps. Almost forgot, Paine don't reply back to this shit, I don't want to see/care what you have to say do your bitching out of my sight, plskthxbai.\n",
      "\n",
      "CLASS THREAT\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "SuPeRTR0LL WiLL LiVe FoReVeR!\n",
      "iF You DoN'T ReSPeCT THe SuPeRTR0LL You WiLL Die You PaTHeTiC FooL!\n",
      "\n",
      "CLASS INSULT\n",
      "asshole and Richard Simmons's asshole, and assisted in the development of a faggoty article on the jizzmaster himself, me, (the latter of which has since undergone faggoty tranny surgery and a tit job. Further revisions to my cock include trying to fuck my mother with it, which I am not entirely happy about, but heck, it's a mom I remind you all I am a faggot who wouldn't risk pissing with the seat down, so you can tell my nickname is a faggoty attempt to appear edgy. I weigh 450kg..\n",
      "\n",
      "CLASS IDENTITY_HATE\n",
      "so, who the fuck gives a damn, you dipshitted lesbian?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in classes_:\n",
    "    print('CLASS', i.upper())\n",
    "    tmp = np.asarray(train[train[i] == 1].comment_text)\n",
    "    print(tmp[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comments contain IP-addresses, user names, urls and a lot of other mess. (better to clean up with regex, etc)\n",
    "* Also some comments contain lots of repetitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to add amount of negative words as feature. Here lies dictionary: https://github.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/blob/master/data/opinion-lexicon-English/negative-words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_words = [i[:-1] for i in open('negative-words.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words_counts = train.comment_text.apply(lambda a: len([i for i in a.lower().split() if i in neg_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tokenizing with TweetTokenizer NLTK. (seem to be cool tool:D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beautify_text(s):\n",
    "    # Removes all characters from string except letters and digits and convert letters to lowercase\n",
    "    s = re.sub(\"[^a-zA-Z0-9]\", \" \", s.lower())\n",
    "    # Remove new lines\n",
    "    s = re.sub(\"\\\\n\",\"\", s)\n",
    "    # Change urls\n",
    "    s = re.sub(\"[a-zA-Z0-9]*(https://)[a-zA-Z0-9.]*\", \"url\", s)\n",
    "    # Remove IPs\n",
    "    s = re.sub(\"\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}\",\"\", s)\n",
    "    # Remove usernames\n",
    "    s = re.sub(\"\\[\\[.*\\]\",\"\", s)\n",
    "    # Remove numbers\n",
    "    s = re.sub(\"\\\\b[0-9]+\\\\b\", \"\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beautiful_text_tr = train.comment_text.apply(beautify_text)\n",
    "beautiful_text_ts = test.comment_text.apply(beautify_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_tr = [tt.tokenize(i) for i in beautiful_text_tr]\n",
    "words_ts = [tt.tokenize(i) for i in beautiful_text_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_tr = [[ps.stem(j) for j in i] for i in words_tr]\n",
    "words_tr = [[wnl.lemmatize(j) for j in i] for i in words_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_ts = [[ps.stem(j) for j in i] for i in words_ts]\n",
    "words_ts = [[wnl.lemmatize(j) for j in i] for i in words_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_tr = [[i for i in j if i not in stopwords.words('english')] for j in words_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_ts = [[i for i in j if i not in stopwords.words('english')] for j in words_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train_new = [' '.join(i) for i in words_tr]\n",
    "text_test_new = [' '.join(i) for i in words_ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF using n_gram from 1 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=50,  max_features=30000, \n",
    "            strip_accents='unicode', analyzer='word',ngram_range=(1,3),\n",
    "            use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "            stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ = tfv.fit_transform(text_train_new)\n",
    "test_ = tfv.transform(text_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For embedings I'm gonna use *bag-of-means* (https://arxiv.org/pdf/1509.01626.pdf)<br>\n",
    "<p>\"We also have an experimental model that uses k-means on word2vec learnt from the training subset of each dataset, and then use these learnt means as representatives of the clustered words. We take into consideration all the words that appeared more than 5 times in the training subset. The bag-of-means features are computed the same way as in the bag-of-words model. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(words_tr, min_count=100, size=500)\n",
    "word_vectors = model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=2800)\n",
    "idx = kmeans_model.fit_predict(word_vectors)\n",
    "word_centroid_map = dict(zip(model.wv.index2word, idx ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fuck', 1.0),\n",
       " ('retard', 0.6874533891677856),\n",
       " ('asshol', 0.6376489400863647),\n",
       " ('motherfuck', 0.617753267288208),\n",
       " ('cunt', 0.6025792956352234),\n",
       " ('garbag', 0.5999402403831482),\n",
       " ('bitch', 0.5947405695915222),\n",
       " ('shut', 0.5876146554946899),\n",
       " ('shit', 0.5849085450172424),\n",
       " ('damn', 0.582467257976532)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(kmeans_model.cluster_centers_[540])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_dim = 500\n",
    "embedding_matrix = np.zeros((len(kmeans_model.cluster_centers_), vector_dim))\n",
    "for i in range(len(kmeans_model.cluster_centers_)):\n",
    "    embedding_vector = kmeans_model.cluster_centers_[i]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train ,y_eval = train_test_split(train_, train[classes_].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_LSTM():\n",
    "    embed_size = 500\n",
    "    max_features = 2800\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(max_features, embed_size, weights=[embedding_matrix]))\n",
    "    model_lstm.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "    model_lstm.add(GlobalMaxPool1D())\n",
    "    model_lstm.add(Dropout(0.25))\n",
    "    model_lstm.add(Dense(50, activation=\"relu\"))\n",
    "    model_lstm.add(Dropout(0.25))\n",
    "    model_lstm.add(Dense(6, activation=\"sigmoid\"))\n",
    "    model_lstm.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_1 = model_LSTM()\n",
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76680, 8636)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_1.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_eval, y_eval),\n",
    "            callbacks=[early], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's first try Conv+LSTM NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "* Using *sigmoid* on last layer instead of *softmax* 'cause we want probability of each class. So we are using sigmoid on final layer, which gives output in range 0 to 1. If our aim was to find the class, then we will have used softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
