{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Майнор \"Прикладные задачи анализа данных\"\n",
    "## Домашнее задание 2 [10 баллов] до 23:59 22.03.2018. Предсказание цены акции по экономическим новостям\n",
    "\n",
    "\n",
    "В этом домашнем задании вы попытаетесь предсказать рост цены акции компании Газпром по новостям о компании. Домашнее задание состоит из трех частей:\n",
    "1. Предварительная обработка текстов и эксплоративный анализ\n",
    "2. Baseline алгоритм\n",
    "3. Творческая часть\n",
    "\n",
    "Все три части можно считать независимыми – вы можете сделать одну или две из них, однако мы настоятельно советуем выполнить все три. Все инструкции по выполнению домашнего задания – ниже. \n",
    "\n",
    "\n",
    "\n",
    "Входные данные:\n",
    "* Новости о компании \"Газпром\", начиная с 2010 года\n",
    "* Стоимость акций компании \"Газпром\" на ММВБ, начиная с 2010 года\n",
    "    * цена открытия (Open)\n",
    "    * цена закрытия (ClosingPrice)\n",
    "    * максимальная цена за день (DailyHigh)\n",
    "    * минимальная цена за день (DailyLow) \n",
    "    * объем бумаг (VolumePcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, make_scorer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09.11.2017</td>\n",
       "      <td>Компания рассчитывает на решение по газовому с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.11.2017</td>\n",
       "      <td>Как и предполагал “Ъ”, «Газпром», воспользова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.11.2017</td>\n",
       "      <td>Новая редакция американских санкций ставит по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.10.2017</td>\n",
       "      <td>Как стало известно “Ъ”, известный на рынке ри...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10.2017</td>\n",
       "      <td>НОВАТЭК, который через пять лет собирается за...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text\n",
       "0  09.11.2017  Компания рассчитывает на решение по газовому с...\n",
       "1  08.11.2017   Как и предполагал “Ъ”, «Газпром», воспользова...\n",
       "2  01.11.2017   Новая редакция американских санкций ставит по...\n",
       "3  30.10.2017   Как стало известно “Ъ”, известный на рынке ри...\n",
       "4  23.10.2017   НОВАТЭК, который через пять лет собирается за..."
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>closingprice</th>\n",
       "      <th>dailyhigh</th>\n",
       "      <th>dailylow</th>\n",
       "      <th>volumepcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08.12.2017</td>\n",
       "      <td>133,43000</td>\n",
       "      <td>132,60000</td>\n",
       "      <td>133,90000</td>\n",
       "      <td>132,00000</td>\n",
       "      <td>16037970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07.12.2017</td>\n",
       "      <td>133,70000</td>\n",
       "      <td>133,02000</td>\n",
       "      <td>133,87000</td>\n",
       "      <td>132,81000</td>\n",
       "      <td>18198430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06.12.2017</td>\n",
       "      <td>133,33000</td>\n",
       "      <td>134,00000</td>\n",
       "      <td>134,29000</td>\n",
       "      <td>132,91000</td>\n",
       "      <td>14641730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05.12.2017</td>\n",
       "      <td>133,48000</td>\n",
       "      <td>133,65000</td>\n",
       "      <td>133,99000</td>\n",
       "      <td>132,78000</td>\n",
       "      <td>12684800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04.12.2017</td>\n",
       "      <td>133,01000</td>\n",
       "      <td>133,77000</td>\n",
       "      <td>134,00000</td>\n",
       "      <td>131,93000</td>\n",
       "      <td>17818980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01.12.2017</td>\n",
       "      <td>132,49000</td>\n",
       "      <td>133,02000</td>\n",
       "      <td>133,32000</td>\n",
       "      <td>131,72000</td>\n",
       "      <td>24755830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.11.2017</td>\n",
       "      <td>133,00000</td>\n",
       "      <td>132,15000</td>\n",
       "      <td>134,31000</td>\n",
       "      <td>132,00000</td>\n",
       "      <td>40024830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.11.2017</td>\n",
       "      <td>134,85000</td>\n",
       "      <td>133,55000</td>\n",
       "      <td>134,86000</td>\n",
       "      <td>132,97000</td>\n",
       "      <td>27263040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28.11.2017</td>\n",
       "      <td>133,23000</td>\n",
       "      <td>135,18000</td>\n",
       "      <td>135,18000</td>\n",
       "      <td>132,55000</td>\n",
       "      <td>26663710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.11.2017</td>\n",
       "      <td>133,69000</td>\n",
       "      <td>133,50000</td>\n",
       "      <td>135,19000</td>\n",
       "      <td>132,80000</td>\n",
       "      <td>27713150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open closingprice  dailyhigh   dailylow  volumepcs\n",
       "0  08.12.2017  133,43000    132,60000  133,90000  132,00000   16037970\n",
       "1  07.12.2017  133,70000    133,02000  133,87000  132,81000   18198430\n",
       "2  06.12.2017  133,33000    134,00000  134,29000  132,91000   14641730\n",
       "3  05.12.2017  133,48000    133,65000  133,99000  132,78000   12684800\n",
       "4  04.12.2017  133,01000    133,77000  134,00000  131,93000   17818980\n",
       "5  01.12.2017  132,49000    133,02000  133,32000  131,72000   24755830\n",
       "6  30.11.2017  133,00000    132,15000  134,31000  132,00000   40024830\n",
       "7  29.11.2017  134,85000    133,55000  134,86000  132,97000   27263040\n",
       "8  28.11.2017  133,23000    135,18000  135,18000  132,55000   26663710\n",
       "9  27.11.2017  133,69000    133,50000  135,19000  132,80000   27713150"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all = pd.read_csv('gazprom_prices.csv', sep=';')\n",
    "pr_all.columns = [i.lower() for i in pr_all.columns]\n",
    "pr_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date            object\n",
       "open            object\n",
       "closingprice    object\n",
       "dailyhigh       object\n",
       "dailylow        object\n",
       "volumepcs        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем все objects в float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_all['open'] = pr_all['open'].apply(lambda a: str(a).replace(',', '.'))\n",
    "pr_all['closingprice'] = pr_all['closingprice'].apply(lambda a: str(a).replace(',', '.'))\n",
    "pr_all['dailyhigh'] = pr_all['dailyhigh'].apply(lambda a: str(a).replace(',', '.'))\n",
    "pr_all['dailylow'] = pr_all['dailylow'].apply(lambda a: str(a).replace(',', '.'))\n",
    "\n",
    "pr_all[['open', 'closingprice', 'dailyhigh', 'dailylow']] = pr_all[['open', 'closingprice', 'dailyhigh', 'dailylow']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             object\n",
       "open            float64\n",
       "closingprice    float64\n",
       "dailyhigh       float64\n",
       "dailylow        float64\n",
       "volumepcs         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Часть 1. Вводная [3 балла]\n",
    "\n",
    "Проведите предобработку текстов: если считаете нужным, выполните токенизацию, приведение к нижнему регистру, лемматизацию и/или стемминг. Ответьте на следующие вопросы:\n",
    "* Есть ли корреляция между средней длинной текста за день и ценой закрытия?\n",
    "* Есть ли корреляция между количеством упоминаний Алексея Миллера  и ценой закрытия? Учтите разные варианты написания имени.\n",
    "* Упоминаний какого газопровода в статьях больше: \n",
    "    * \"северный поток\"\n",
    "    * \"турецкий поток\"?\n",
    "* Кого упоминают чаще:\n",
    "    * Алексея Миллера\n",
    "    * Владимира Путина?\n",
    "* О каких санкциях пишут в статьях?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def beautify_text(s):\n",
    "    s = re.sub(\"[^а-яА-Я0-9]\", \" \", s.lower())\n",
    "    s = s.replace('\\n', '')\n",
    "    return s\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    mystem = Mystem()\n",
    "    sentc = [word_tokenize((beautify_text(i))) for i in text]\n",
    "    filtered_sentc = [i for i in sentc if i not in stopwords.words('russian')]\n",
    "    lemmatized_sentc = [[mystem.lemmatize(j)[0] for j in i] for i in sentc]\n",
    "    \n",
    "    return lemmatized_sentc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_pr = preprocess_text(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text_preproc'] = [' '.join(i) for i in text_pr]\n",
    "df['text_len'] = df.text.apply(lambda a: len(a))\n",
    "df['miller'] = [' '.join(i).count('алексей миллер') for i in text_pr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_all = pr_all.sort_values(by=['date'])\n",
    "df = df.sort_values(by=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>closingprice</th>\n",
       "      <th>dailyhigh</th>\n",
       "      <th>dailylow</th>\n",
       "      <th>volumepcs</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preproc</th>\n",
       "      <th>text_len</th>\n",
       "      <th>miller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.02.2010</td>\n",
       "      <td>184.74</td>\n",
       "      <td>189.85</td>\n",
       "      <td>190.40</td>\n",
       "      <td>183.50</td>\n",
       "      <td>76298175</td>\n",
       "      <td>\"Газпром\" не исключает в 2010 г. выпуска обли...</td>\n",
       "      <td>газпром не исключать в 2010 г выпуск облигация...</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.02.2011</td>\n",
       "      <td>198.41</td>\n",
       "      <td>204.91</td>\n",
       "      <td>205.00</td>\n",
       "      <td>197.80</td>\n",
       "      <td>87981195</td>\n",
       "      <td>На российском ТВ — вновь дефицит рекламного в...</td>\n",
       "      <td>на российский тв вновь дефицит рекламный время...</td>\n",
       "      <td>586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.02.2012</td>\n",
       "      <td>183.00</td>\n",
       "      <td>185.54</td>\n",
       "      <td>186.75</td>\n",
       "      <td>182.60</td>\n",
       "      <td>44145020</td>\n",
       "      <td>Федеральная антимонопольная служба (ФАС) приз...</td>\n",
       "      <td>федеральный антимонопольный служба фас признав...</td>\n",
       "      <td>857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.02.2013</td>\n",
       "      <td>142.45</td>\n",
       "      <td>142.41</td>\n",
       "      <td>143.47</td>\n",
       "      <td>141.87</td>\n",
       "      <td>27154010</td>\n",
       "      <td>Правительство выдвинуло 14 кандидатов на 11 м...</td>\n",
       "      <td>правительство выдвигать 14 кандидат на 11 мест...</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.02.2016</td>\n",
       "      <td>136.01</td>\n",
       "      <td>133.90</td>\n",
       "      <td>136.34</td>\n",
       "      <td>132.82</td>\n",
       "      <td>31931470</td>\n",
       "      <td>\"Газпром\" не исключил участия в реализации эк...</td>\n",
       "      <td>газпром не исключать участие в реализация эксп...</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01.02.2017</td>\n",
       "      <td>150.00</td>\n",
       "      <td>149.65</td>\n",
       "      <td>150.38</td>\n",
       "      <td>148.32</td>\n",
       "      <td>20916550</td>\n",
       "      <td>Сегодня исследовательская компания Brand Fina...</td>\n",
       "      <td>сегодня исследовательский компания опубликовыв...</td>\n",
       "      <td>972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01.03.2012</td>\n",
       "      <td>192.53</td>\n",
       "      <td>194.01</td>\n",
       "      <td>194.27</td>\n",
       "      <td>191.76</td>\n",
       "      <td>31594230</td>\n",
       "      <td>\"Газпром\" скорректирует условия поставок росс...</td>\n",
       "      <td>газпром скорректировать условие поставка росси...</td>\n",
       "      <td>983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01.03.2017</td>\n",
       "      <td>133.50</td>\n",
       "      <td>133.85</td>\n",
       "      <td>134.99</td>\n",
       "      <td>133.00</td>\n",
       "      <td>38131650</td>\n",
       "      <td>Правление  «Газпрома» предложило сохранить ди...</td>\n",
       "      <td>правление газпром предлагать сохранять дивиден...</td>\n",
       "      <td>1167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01.04.2014</td>\n",
       "      <td>135.90</td>\n",
       "      <td>135.89</td>\n",
       "      <td>136.73</td>\n",
       "      <td>133.84</td>\n",
       "      <td>64684830</td>\n",
       "      <td>Moody's Investors Service поставило рейтинги ...</td>\n",
       "      <td>поставлять рейтинг оао газпром и оао роснефть ...</td>\n",
       "      <td>1398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01.04.2016</td>\n",
       "      <td>147.02</td>\n",
       "      <td>147.20</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.93</td>\n",
       "      <td>36517160</td>\n",
       "      <td>\"Газпром-медиа\", управляющий телеканалами ТНТ...</td>\n",
       "      <td>газпром медиа управлять телеканал тнт нтв ради...</td>\n",
       "      <td>789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open  closingprice  dailyhigh  dailylow  volumepcs  \\\n",
       "0  01.02.2010  184.74        189.85     190.40    183.50   76298175   \n",
       "1  01.02.2011  198.41        204.91     205.00    197.80   87981195   \n",
       "2  01.02.2012  183.00        185.54     186.75    182.60   44145020   \n",
       "3  01.02.2013  142.45        142.41     143.47    141.87   27154010   \n",
       "4  01.02.2016  136.01        133.90     136.34    132.82   31931470   \n",
       "5  01.02.2017  150.00        149.65     150.38    148.32   20916550   \n",
       "6  01.03.2012  192.53        194.01     194.27    191.76   31594230   \n",
       "7  01.03.2017  133.50        133.85     134.99    133.00   38131650   \n",
       "8  01.04.2014  135.90        135.89     136.73    133.84   64684830   \n",
       "9  01.04.2016  147.02        147.20     147.50    143.93   36517160   \n",
       "\n",
       "                                                text  \\\n",
       "0   \"Газпром\" не исключает в 2010 г. выпуска обли...   \n",
       "1   На российском ТВ — вновь дефицит рекламного в...   \n",
       "2   Федеральная антимонопольная служба (ФАС) приз...   \n",
       "3   Правительство выдвинуло 14 кандидатов на 11 м...   \n",
       "4   \"Газпром\" не исключил участия в реализации эк...   \n",
       "5   Сегодня исследовательская компания Brand Fina...   \n",
       "6   \"Газпром\" скорректирует условия поставок росс...   \n",
       "7   Правление  «Газпрома» предложило сохранить ди...   \n",
       "8   Moody's Investors Service поставило рейтинги ...   \n",
       "9   \"Газпром-медиа\", управляющий телеканалами ТНТ...   \n",
       "\n",
       "                                        text_preproc  text_len  miller  \n",
       "0  газпром не исключать в 2010 г выпуск облигация...       256       0  \n",
       "1  на российский тв вновь дефицит рекламный время...       586       0  \n",
       "2  федеральный антимонопольный служба фас признав...       857       0  \n",
       "3  правительство выдвигать 14 кандидат на 11 мест...       171       0  \n",
       "4  газпром не исключать участие в реализация эксп...      1224       0  \n",
       "5  сегодня исследовательский компания опубликовыв...       972       0  \n",
       "6  газпром скорректировать условие поставка росси...       983       2  \n",
       "7  правление газпром предлагать сохранять дивиден...      1167       0  \n",
       "8  поставлять рейтинг оао газпром и оао роснефть ...      1398       0  \n",
       "9  газпром медиа управлять телеканал тнт нтв ради...       789       0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gasprom_info = pd.merge(pr_all, df, on=['date'])\n",
    "gasprom_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014158394621268122"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gasprom_info.corr()['text_len']['closingprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0032372019497298519"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gasprom_info.corr()['miller']['closingprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Северный поток: 15 Турецкий поток: 39\n"
     ]
    }
   ],
   "source": [
    "print('Северный поток:', sum([' '.join(i).count('северный поток') for i in text_pr]), \n",
    "'Турецкий поток:', sum([' '.join(i).count('турецкий поток') for i in text_pr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Алексей Миллер: 125 Владимир Путин: 67\n"
     ]
    }
   ],
   "source": [
    "print('Алексей Миллер:', sum([' '.join(i).count('алексей миллер') for i in text_pr]), \n",
    "'Владимир Путин:', sum([' '.join(i).count('владимир путин') for i in text_pr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Санкции в статьях: {'персональный', 'очередной', 'антироссийский', 'западный', 'финансовый', 'экономический', 'штрафной', 'американский', 'международный'}\n"
     ]
    }
   ],
   "source": [
    "sanc_set = set()\n",
    "for i in text_pr:\n",
    "    if 'санкция' in i:\n",
    "        for j in i:\n",
    "            if j == 'санкция':\n",
    "                break\n",
    "            sanc = j\n",
    "        if sanc[-2:] in ['ий', 'ой', 'ый']:\n",
    "            sanc_set.add(sanc)\n",
    "            \n",
    "print('Санкции в статьях:', sanc_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Часть 2. Классификационная [3 балла]\n",
    "Вам предстоит решить следующую задачу: по текстам новостей за день определить, вырастет или понизится цена закрытия.\n",
    "Для этого:\n",
    "* бинаризуйте признак \"цена закрытия\":  новый признак ClosingPrice_bin равен 1, если по сравнению со вчера цена не упала, и 0 – в обратном случае;\n",
    "* составьте обучающее и тестовое множество: данные до начала 2016 года используются для обучения, данные с 2016 года и позже – для тестирования.\n",
    "\n",
    "Таким образом, в каждлый момент времени мы знаем: \n",
    "* ClosingPrice_bin – бинарый целевой признак\n",
    "* слова из статей, опубликованных в этот день – объясняющие признаки\n",
    "\n",
    "В этой части задания вам нужно сделать baseline алгоритм и попытаться его улучшить в следующей части. \n",
    "\n",
    "Используйте любой известный вам алгоритм классификации текстов для того, Используйте $tf-idf$ преобразование, сингулярное разложение, нормировку признакого пространства и любые другие техники обработки данных, которые вы считаете нужным. Используйте accuracy и F-measure для оценки качества классификации. Покажите, как  $tf-idf$ преобразование или сингулярное разложение или любая другая использованная вами техника влияет на качество классификации.\n",
    "Если у выбранного вами алгоритма есть гиперпараметры (например, $\\alpha$ в преобразовании Лапласа для метода наивного Байеса), покажите, как изменение гиперпараметра влияет на качество классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gasprom_info.loc[0, 'closingprice_bin'] = 0\n",
    "for i in range(1, len(gasprom_info)):\n",
    "    gasprom_info.loc[i, 'closingprice_bin'] = (1 + (np.sign(gasprom_info.loc[i, 'closingprice'] - gasprom_info.loc[(i-1), 'closingprice']))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>closingprice</th>\n",
       "      <th>dailyhigh</th>\n",
       "      <th>dailylow</th>\n",
       "      <th>volumepcs</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preproc</th>\n",
       "      <th>text_len</th>\n",
       "      <th>miller</th>\n",
       "      <th>closingprice_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.02.2010</td>\n",
       "      <td>184.74</td>\n",
       "      <td>189.85</td>\n",
       "      <td>190.40</td>\n",
       "      <td>183.50</td>\n",
       "      <td>76298175</td>\n",
       "      <td>\"Газпром\" не исключает в 2010 г. выпуска обли...</td>\n",
       "      <td>газпром не исключать в 2010 г выпуск облигация...</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.02.2011</td>\n",
       "      <td>198.41</td>\n",
       "      <td>204.91</td>\n",
       "      <td>205.00</td>\n",
       "      <td>197.80</td>\n",
       "      <td>87981195</td>\n",
       "      <td>На российском ТВ — вновь дефицит рекламного в...</td>\n",
       "      <td>на российский тв вновь дефицит рекламный время...</td>\n",
       "      <td>586</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.02.2012</td>\n",
       "      <td>183.00</td>\n",
       "      <td>185.54</td>\n",
       "      <td>186.75</td>\n",
       "      <td>182.60</td>\n",
       "      <td>44145020</td>\n",
       "      <td>Федеральная антимонопольная служба (ФАС) приз...</td>\n",
       "      <td>федеральный антимонопольный служба фас признав...</td>\n",
       "      <td>857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.02.2013</td>\n",
       "      <td>142.45</td>\n",
       "      <td>142.41</td>\n",
       "      <td>143.47</td>\n",
       "      <td>141.87</td>\n",
       "      <td>27154010</td>\n",
       "      <td>Правительство выдвинуло 14 кандидатов на 11 м...</td>\n",
       "      <td>правительство выдвигать 14 кандидат на 11 мест...</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.02.2016</td>\n",
       "      <td>136.01</td>\n",
       "      <td>133.90</td>\n",
       "      <td>136.34</td>\n",
       "      <td>132.82</td>\n",
       "      <td>31931470</td>\n",
       "      <td>\"Газпром\" не исключил участия в реализации эк...</td>\n",
       "      <td>газпром не исключать участие в реализация эксп...</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open  closingprice  dailyhigh  dailylow  volumepcs  \\\n",
       "0  01.02.2010  184.74        189.85     190.40    183.50   76298175   \n",
       "1  01.02.2011  198.41        204.91     205.00    197.80   87981195   \n",
       "2  01.02.2012  183.00        185.54     186.75    182.60   44145020   \n",
       "3  01.02.2013  142.45        142.41     143.47    141.87   27154010   \n",
       "4  01.02.2016  136.01        133.90     136.34    132.82   31931470   \n",
       "\n",
       "                                                text  \\\n",
       "0   \"Газпром\" не исключает в 2010 г. выпуска обли...   \n",
       "1   На российском ТВ — вновь дефицит рекламного в...   \n",
       "2   Федеральная антимонопольная служба (ФАС) приз...   \n",
       "3   Правительство выдвинуло 14 кандидатов на 11 м...   \n",
       "4   \"Газпром\" не исключил участия в реализации эк...   \n",
       "\n",
       "                                        text_preproc  text_len  miller  \\\n",
       "0  газпром не исключать в 2010 г выпуск облигация...       256       0   \n",
       "1  на российский тв вновь дефицит рекламный время...       586       0   \n",
       "2  федеральный антимонопольный служба фас признав...       857       0   \n",
       "3  правительство выдвигать 14 кандидат на 11 мест...       171       0   \n",
       "4  газпром не исключать участие в реализация эксп...      1224       0   \n",
       "\n",
       "   closingprice_bin  \n",
       "0               0.0  \n",
       "1               1.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gasprom_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gasprom_info['date'] = pd.to_datetime(gasprom_info['date'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = gasprom_info[gasprom_info['date'] <= '2016-1-1']['text_preproc'], gasprom_info[gasprom_info['date'] <= '2016-1-1']['closingprice_bin']\n",
    "X_test, y_test = gasprom_info[gasprom_info['date'] >= '2016-1-1']['text_preproc'], gasprom_info[gasprom_info['date'] >= '2016-1-1']['closingprice_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=10000)\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(X_train)\n",
    "test_word_features = word_vectorizer.transform(X_test)\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=30000)\n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(X_train)\n",
    "test_char_features = char_vectorizer.transform(X_test)\n",
    "\n",
    "train_features = hstack((train_char_features, train_word_features))\n",
    "test_features = hstack((test_char_features, test_word_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg on 10 folds: 0.645452396359\n",
      "Logreg on train: 0.962436548223\n",
      "Logreg on test: 0.464566929134\n"
     ]
    }
   ],
   "source": [
    "shuffle = StratifiedKFold(n_splits=4)\n",
    "lr = LogisticRegression()\n",
    "cv_score = np.mean(cross_val_score(lr, train_features, y_train, cv=shuffle, scoring='f1', n_jobs=1))\n",
    "lr.fit(train_features, y_train)\n",
    "logreg_train_pred = lr.predict(train_features)\n",
    "logreg_test_pred = lr.predict(test_features)\n",
    "print('Logreg on 10 folds:', cv_score)\n",
    "print('Logreg on train:', f1_score(logreg_train_pred, y_train))\n",
    "print('Logreg on test:', f1_score(logreg_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM + hyperopt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "best f1 param: {'kernel': 2}\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "                'kernel': hp.choice('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "              }\n",
    "\n",
    "def objective_svc_f1(params):\n",
    "    model = SVC(kernel=params['kernel'])\n",
    "    \n",
    "    shuffle = KFold()\n",
    "    score = cross_val_score(model, train_features, y_train, cv=shuffle, scoring='f1', n_jobs=1)\n",
    "    return 1-score.mean()\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "print('Fitting model...')\n",
    "best_svm = fmin(objective_svc_f1,\n",
    "            param_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print('best f1 param:', best_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best svm on 10 folds: 0.693255313283\n",
      "Best svm on train: 0.693255982596\n",
      "Best svm on test: 0.521489971347\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf')\n",
    "cv_score = np.mean(cross_val_score(svm, train_features, y_train, cv=shuffle, scoring='f1'))\n",
    "svm.fit(train_features, y_train)\n",
    "svm_train_pred = svm.predict(train_features)\n",
    "svm_test_pred = svm.predict(test_features)\n",
    "print('Best svm on 10 folds:', cv_score)\n",
    "print('Best svm on train:', f1_score(svm_train_pred, y_train))\n",
    "print('Best svm on test:', f1_score(svm_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective_lgbm(params):\n",
    "    params = {\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "    }\n",
    "    \n",
    "    model = lgbm.LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        **params\n",
    "    )\n",
    "    shuffle = KFold()\n",
    "    score = cross_val_score(model, train_features, y_train, cv=shuffle, scoring='f1', n_jobs=1)\n",
    "    return 1-score.mean()\n",
    "\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "best: {'num_leaves': 30.0, 'colsample_bytree': 0.5049119421032009}\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "}\n",
    "\n",
    "print('Fitting model...')\n",
    "best_lgbm = fmin(objective_lgbm,\n",
    "            param_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=4,\n",
    "            trials=trials)\n",
    "print('best:', best_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best svm on 10 folds: 0.584005967598\n",
      "Best svm on train: 1.0\n",
      "Best svm on test: 0.463414634146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobrg/anaconda3/lib/python3.5/site-packages/lightgbm/basic.py:447: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "lgbm_c = lgbm.LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=30 ,\n",
    "        colsample_bytree=0.5049119421032009 )\n",
    "\n",
    "cv_score = np.mean(cross_val_score(lgbm_c, train_features, y_train, cv=10, scoring='f1'))\n",
    "lgbm_c.fit(train_features, y_train)\n",
    "lgbm_train_pred = lgbm_c.predict(train_features)\n",
    "lgbm_test_pred = lgbm_c.predict(test_features)\n",
    "print('Best lgbm on 10 folds:', cv_score)\n",
    "print('Best lgbm on train:', f1_score(lgbm_train_pred, y_train))\n",
    "print('Best lgbm on test:', f1_score(lgbm_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 18322)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 1024)              18762752  \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 19,419,137\n",
      "Trainable params: 19,419,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 720 samples, validate on 181 samples\n",
      "Epoch 1/5\n",
      "720/720 [==============================] - 71s 98ms/step - loss: 0.6928 - acc: 0.5194 - binary_accuracy: 0.5194 - val_loss: 0.6925 - val_acc: 0.5193 - val_binary_accuracy: 0.5193\n",
      "Epoch 2/5\n",
      "720/720 [==============================] - 65s 90ms/step - loss: 0.6854 - acc: 0.5458 - binary_accuracy: 0.5458 - val_loss: 0.6947 - val_acc: 0.5193 - val_binary_accuracy: 0.5193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca463c6cc0>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu', input_shape=(18322, )))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy', metrics.binary_accuracy])\n",
    "    return model\n",
    "model = get_simple_model()\n",
    "model.fit(train_features.todense(), y_train, batch_size=4, epochs=5, verbose=1, validation_split=0.2, callbacks=[EarlyStopping()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52148997134670494"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(model.predict_classes(test_features.todense()).reshape(258), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35271317829457366"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model.predict_classes(test_features.todense()).reshape(258) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Часть 3. Творческая [4 балла]\n",
    "Придумайте и попытайтесь сделать еще что-нибудь, чтобы улучшить качество классификации. \n",
    "Направления развития:\n",
    "* Морфологический признаки: \n",
    "    * использовать в качестве признаков только существительные или только именованные сущности;\n",
    "* Модели скрытых тем:\n",
    "    * использовать в качестве признаков скрытые темы;\n",
    "    * использовать в качестве признаков динамические скрытые темы \n",
    "    пример тут: (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/dtm_example.ipynb)\n",
    "* Синтаксические признаки:\n",
    "    * использовать SOV-тройки в качестве признаков\n",
    "    * кластеризовать SOV-тройки по усредненным эмбеддингам  (обученные word2vec модели можно скачать отсюда: (http://rusvectores.org/ru/models/ или https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) и использовать только центроиды кластеров в качестве признаков\n",
    "* что-нибудь еще     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "MAX_FEATURES = 10000\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings...\n",
      "found 0 word vectors\n"
     ]
    }
   ],
   "source": [
    "print('loading word embeddings...')\n",
    "embeddings_index = {}\n",
    "f = open('wiki.ru.vec', encoding='utf-8')\n",
    "for line in (f):\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('found %s word vectors' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open('wiki.ru.vec'))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "tokenizer.fit_on_texts(X_test)\n",
    "\n",
    "train_data = pad_sequences(sequences=tokenizer.texts_to_sequences(X_train), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data = pad_sequences(sequences=tokenizer.texts_to_sequences(X_test), maxlen=MAX_SEQUENCE_LENGTH)\n",
    " \n",
    "    \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "nb_words = min(MAX_FEATURES, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_FEATURES: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 300)         9000000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 1024)        922624    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 512)         1573376   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               245200    \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 11,741,301\n",
      "Trainable params: 11,741,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_FEATURES, EMBEDDING_DIM))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 181 samples\n",
      "Epoch 1/5\n",
      "720/720 [==============================] - 364s 505ms/step - loss: 0.6948 - acc: 0.5417 - val_loss: 0.6923 - val_acc: 0.5193\n",
      "Epoch 2/5\n",
      "720/720 [==============================] - 347s 481ms/step - loss: 0.6484 - acc: 0.5875 - val_loss: 0.7038 - val_acc: 0.4972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8b4645908>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, y_train, batch_size=4, epochs=5, verbose=1, validation_split=0.2, callbacks=[EarlyStopping()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 500)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22972972972972971"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(model.predict_classes(test_data), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Сдача домашнего задания\n",
    "\n",
    "Дедлайн сдачи домашнего задания:  23:59 22.03.2018. Каждый день просрочки дедлайна штрафуется -1 баллом.\n",
    "\n",
    "Результаты домашнего задания должны быть оформлены в виде отчета в jupyter notebook.\n",
    "Нормальный отчёт должен включать в себя:\n",
    "* Краткую постановку задачи и формулировку задания\n",
    "* Описание минимума необходимой теории и/или описание используемых инструментов \n",
    "* Подробный пошаговый рассказ о проделанной работе\n",
    "* **Аккуратно** оформленные результаты\n",
    "* Подробные и внятные ответы на все заданные вопросы \n",
    "* Внятные выводы – не стоит относится к домашнему заданию как к последовательности сугубо технических шагов, а стоит относится скорее как к небольшому практическому исследованию, у которого есть своя цель и свое назначение.\n",
    "\n",
    "Задание выполняется в группе до трех человек. Не забудьте перечислить фамилии всех, кто работал над домашнем задании, в jupyter notebook.  \n",
    "\n",
    "В случае использования какого-либо строннего источника информации обязательно дайте на него ссылку (поскольку другие тоже могут на него наткнуться). Плагиат наказывается нулём баллов за задание и предвзятым отношением в будущем.\n",
    "\n",
    "\n",
    "При возникновении проблем с выполнением задания обращайтесь с вопросами к преподавателю по семинарским занятиям в вашей группе или у учебным ассистентам.\n",
    "\n",
    "Учебный ассистент по ДЗ 2: Таисия Глушкова (email: glushkovato@gmail.com, telegram: @glushkovato).\n",
    "\n",
    "\n",
    "Небрежное оформление отчета существенно отразится на итоговой оценке. Весь код из отчёта должен быть воспроизводимым, если для этого нужны какие-то дополнительные действия, установленные модули и т.п. — всё это должно быть прописано в отчете в явном виде.\n",
    "\n",
    "Сдача отчетов осуществляется через систему AnyTask.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
